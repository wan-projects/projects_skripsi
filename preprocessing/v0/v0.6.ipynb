{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\wawn1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.9.0.80)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\wawn1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opencv-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\wawn1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\wawn1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\wawn1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\wawn1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\wawn1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\wawn1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\wawn1\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\wawn1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\wawn1\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\wawn1\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wawn1\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmented Data + Convert RGB to Grayscale + Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Augmentasi Selesai!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Path ke direktori dataset\n",
    "dataset_dir = '../data/data_original/javaneseScript_byPhiard/train'\n",
    "output_dir = '../data/data_preprocessing/byPhiard_v1.2'\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=19,\n",
    "    # width_shift_range=0.1,\n",
    "    # height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Membuat folder baru untuk menyimpan hasil augmentasi\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Roberts Operator\n",
    "kernel_roberts_x = np.array([[1, 0], [0, -1]])\n",
    "kernel_roberts_y = np.array([[0, 1], [-1, 0]])\n",
    "\n",
    "# Loop melalui setiap kelas dalam dataset\n",
    "for class_name in os.listdir(dataset_dir):\n",
    "    class_path = os.path.join(dataset_dir, class_name)\n",
    "\n",
    "    # Membuat folder baru untuk setiap kelas di dalam folder output\n",
    "    output_class_path = os.path.join(output_dir, class_name)\n",
    "    if not os.path.exists(output_class_path):\n",
    "        os.makedirs(output_class_path)\n",
    "\n",
    "    # Mendapatkan list file gambar di setiap kelas\n",
    "    image_files = [os.path.join(class_path, file) for file in os.listdir(class_path) if file.endswith(('jpg', 'jpeg', 'png'))]\n",
    "\n",
    "    # Loop melalui setiap file gambar dan augmentasi datanya\n",
    "    for img_path in image_files:\n",
    "        img = image.load_img(img_path, target_size=(224, 224), color_mode=\"rgb\")  # Memuat gambar dengan mode RGB\n",
    "        x = image.img_to_array(img)\n",
    "        x = x.reshape((1,) + x.shape)\n",
    "\n",
    "        # Proses augmented images\n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size=1, save_to_dir=output_class_path,\n",
    "                                  save_prefix=os.path.splitext(os.path.basename(img_path))[0] + '_aug', save_format='png'):\n",
    "            \n",
    "            augmented_img = batch[0]  # Mendapatkan gambar augmented dari batch\n",
    "            gray_img = cv2.cvtColor(augmented_img, cv2.COLOR_RGB2GRAY).astype(np.uint8)  # Konversi RGB ke Grayscale dan ubah ke uint8\n",
    "            \n",
    "            edges_roberts_x = cv2.filter2D(gray_img, cv2.CV_64F, kernel_roberts_x)\n",
    "            edges_roberts_y = cv2.filter2D(gray_img, cv2.CV_64F, kernel_roberts_y)\n",
    "            magnitude_roberts = np.sqrt(edges_roberts_x**2 + edges_roberts_y**2)\n",
    "\n",
    "            # Thresholding for Edge Detection Results\n",
    "            threshold = 50\n",
    "            detected_edges_roberts = np.zeros_like(magnitude_roberts)\n",
    "            detected_edges_roberts[magnitude_roberts > threshold] = 255\n",
    "            \n",
    "            # Simpan gambar hasil augmentasi dengan tepi yang terdeteksi\n",
    "            cv2.imwrite(os.path.join(output_class_path, os.path.splitext(os.path.basename(img_path))[0] + f'_aug_{i}_edges.png'), detected_edges_roberts)\n",
    "            \n",
    "            i += 1\n",
    "            if i >= 250:\n",
    "                break\n",
    "        break\n",
    "\n",
    "print(f\"\\nAugmentasi Selesai!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelas ba: 495 gambar\n",
      "Kelas ca: 499 gambar\n",
      "Kelas da: 495 gambar\n",
      "Kelas dha: 497 gambar\n",
      "Kelas ga: 497 gambar\n",
      "Kelas ha: 497 gambar\n",
      "Kelas ja: 498 gambar\n",
      "Kelas ka: 497 gambar\n",
      "Kelas la: 495 gambar\n",
      "Kelas ma: 498 gambar\n",
      "Kelas na: 498 gambar\n",
      "Kelas nga: 498 gambar\n",
      "Kelas nya: 495 gambar\n",
      "Kelas pa: 497 gambar\n",
      "Kelas ra: 500 gambar\n",
      "Kelas sa: 498 gambar\n",
      "Kelas ta: 495 gambar\n",
      "Kelas tha: 498 gambar\n",
      "Kelas wa: 499 gambar\n",
      "Kelas ya: 497 gambar\n"
     ]
    }
   ],
   "source": [
    "# Dictionary untuk menyimpan jumlah data di setiap kelas\n",
    "kelas_data_count = {}\n",
    "\n",
    "# Loop melalui setiap kelas di dalam folder output\n",
    "for class_name in os.listdir(output_dir):\n",
    "    class_path = os.path.join(output_dir, class_name)\n",
    "    \n",
    "    # Menghitung jumlah file gambar di setiap kelas\n",
    "    num_images = len([file for file in os.listdir(class_path) if file.endswith(('jpg', 'jpeg', 'png'))])\n",
    "    \n",
    "    # Menyimpan jumlah data di setiap kelas ke dalam dictionary\n",
    "    kelas_data_count[class_name] = num_images\n",
    "\n",
    "# Menampilkan jumlah data di setiap kelas\n",
    "for class_name, count in kelas_data_count.items():\n",
    "    print(f\"Kelas {class_name}: {count} gambar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aksara ba jumlah: 500\n",
      "Aksara ca jumlah: 500\n",
      "Aksara da jumlah: 500\n",
      "Aksara dha jumlah: 500\n",
      "Aksara ga jumlah: 500\n",
      "Aksara ha jumlah: 500\n",
      "Aksara ja jumlah: 500\n",
      "Aksara ka jumlah: 500\n",
      "Aksara la jumlah: 500\n",
      "Aksara ma jumlah: 500\n",
      "Aksara na jumlah: 500\n",
      "Aksara nga jumlah: 500\n",
      "Aksara nya jumlah: 500\n",
      "Aksara pa jumlah: 500\n",
      "Aksara ra jumlah: 500\n",
      "Aksara sa jumlah: 500\n",
      "Aksara ta jumlah: 500\n",
      "Aksara tha jumlah: 500\n",
      "Aksara wa jumlah: 500\n",
      "Aksara ya jumlah: 500\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "import shutil\n",
    "\n",
    "# Path dataset\n",
    "data = output_dir\n",
    "\n",
    "# List kelas\n",
    "kelas_aksara = ['ba', 'ca', 'da', 'dha', 'ga', 'ha', 'ja', 'ka', 'la', 'ma', 'na', 'nga', 'nya', 'pa', 'ra', 'sa', 'ta', 'tha', 'wa', 'ya']\n",
    "\n",
    "# Target jumlah gambar per kelas\n",
    "target_jumlah = 500\n",
    "\n",
    "# Loop untuk setiap kelas\n",
    "for kelas in kelas_aksara:\n",
    "    # Path kelas\n",
    "    kelas_path = os.path.join(data, kelas)\n",
    "    \n",
    "    # Jumlah gambar saat ini\n",
    "    jumlah_gambar = len(os.listdir(kelas_path))\n",
    "    \n",
    "    # Selisih gambar yang perlu ditambahkan\n",
    "    selisih = target_jumlah - jumlah_gambar\n",
    "    \n",
    "    # Jika selisih positif, lakukan oversampling\n",
    "    if selisih > 0:\n",
    "        # Ambil sampel acak dari gambar yang sudah ada\n",
    "        gambar_oversampling = random.sample(os.listdir(kelas_path), selisih)\n",
    "        \n",
    "        # Copy gambar oversampling ke dalam kelas\n",
    "        for gambar in gambar_oversampling:\n",
    "            source_path = os.path.join(kelas_path, gambar)\n",
    "            \n",
    "            # Generate sufiks acak\n",
    "            sufiks_acak = ''.join(random.choices(string.ascii_letters + string.digits, k=8))\n",
    "            \n",
    "            # Tentukan path tujuan dengan menambahkan sufiks acak\n",
    "            target_path = os.path.join(kelas_path, f'{os.path.splitext(gambar)[0]}_{sufiks_acak}{os.path.splitext(gambar)[1]}')\n",
    "            \n",
    "            # Salin gambar ke target path\n",
    "            shutil.copy(source_path, target_path)\n",
    "\n",
    "# Cetak ulang jumlah gambar per kelas setelah penyamaan\n",
    "for kelas in kelas_aksara:\n",
    "    kelas_path = os.path.join(data, kelas)\n",
    "    jumlah_gambar = len(os.listdir(kelas_path))\n",
    "    print(f'Aksara {kelas} jumlah: {jumlah_gambar}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Path ke direktori utama yang berisi sub-direktori untuk masing-masing kelas\n",
    "main_data_dir = output_dir\n",
    "\n",
    "# Path ke direktori output untuk train dan test set\n",
    "path_dir = '../data/data_preprocessing/data_split_v0.0/'\n",
    "\n",
    "# Membuat sub-direktori train dan test\n",
    "train_dir = os.path.join(path_dir, 'train')\n",
    "test_dir = os.path.join(path_dir, 'test')\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Loop melalui masing-masing kelas (diasumsikan ada 20 kelas)\n",
    "for class_name in os.listdir(main_data_dir):\n",
    "    class_path = os.path.join(main_data_dir, class_name)\n",
    "    \n",
    "    # Mendapatkan list file untuk kelas tertentu\n",
    "    files = os.listdir(class_path)\n",
    "    \n",
    "    # Membagi data menjadi train dan test set\n",
    "    train_files, test_files = train_test_split(files, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Membuat sub-direktori untuk masing-masing kelas di train dan test set\n",
    "    train_class_dir = os.path.join(train_dir, class_name)\n",
    "    test_class_dir = os.path.join(test_dir, class_name)\n",
    "    \n",
    "    os.makedirs(train_class_dir, exist_ok=True)\n",
    "    os.makedirs(test_class_dir, exist_ok=True)\n",
    "    \n",
    "    # Menyalin file ke dalam masing-masing sub-direktori\n",
    "    for file in train_files:\n",
    "        shutil.copy(os.path.join(class_path, file), os.path.join(train_class_dir, file))\n",
    "    \n",
    "    for file in test_files:\n",
    "        shutil.copy(os.path.join(class_path, file), os.path.join(test_class_dir, file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
