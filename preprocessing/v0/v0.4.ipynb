{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b67a9bed-f742-4161-9cb8-e75fb179ba81",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17c0a86b-36d7-41f5-b4eb-4833dd8809ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.preprocessing import image\n",
    "# import os\n",
    "\n",
    "# # Path ke direktori dataset\n",
    "# dataset_dir = './byPhiard'\n",
    "# output_dir = './keras_aug'\n",
    "\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rescale=1./255,\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.1,\n",
    "#     height_shift_range=0.1,\n",
    "#     shear_range=0.1,\n",
    "#     zoom_range=0.1,\n",
    "#     horizontal_flip=True,\n",
    "#     fill_mode='nearest'\n",
    "# )\n",
    "\n",
    "# # Membuat folder baru untuk menyimpan hasil augmentasi\n",
    "# if not os.path.exists(output_dir):\n",
    "#     os.makedirs(output_dir)\n",
    "\n",
    "# # Loop melalui setiap kelas dalam dataset\n",
    "# for class_name in os.listdir(dataset_dir):\n",
    "#     class_path = os.path.join(dataset_dir, class_name)\n",
    "\n",
    "#     # Membuat folder baru untuk setiap kelas di dalam folder output\n",
    "#     output_class_path = os.path.join(output_dir, class_name)\n",
    "#     if not os.path.exists(output_class_path):\n",
    "#         os.makedirs(output_class_path)\n",
    "\n",
    "#     # Mendapatkan list file gambar di setiap kelas\n",
    "#     image_files = [os.path.join(class_path, file) for file in os.listdir(class_path) if file.endswith(('jpg', 'jpeg', 'png'))]\n",
    "\n",
    "#     # Loop melalui setiap file gambar dan augmentasi datanya\n",
    "#     for img_path in image_files:\n",
    "#         img = image.load_img(img_path, target_size=(224, 224))\n",
    "#         x = image.img_to_array(img)\n",
    "#         x = x.reshape((1,) + x.shape)\n",
    "\n",
    "#         # Menghasilkan 5 augmented images per gambar\n",
    "#         i = 0\n",
    "#         for batch in datagen.flow(x, batch_size=1, save_to_dir=output_class_path,\n",
    "#                                   save_prefix=os.path.splitext(os.path.basename(img_path))[0] + '_aug', save_format='png'):\n",
    "#             i += 1\n",
    "#             if i >= 5:  \n",
    "#                 break\n",
    "#                    \n",
    "# print(f\"\\nAugmentasi Selesai!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "602ab7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Augmentasi Selesai!\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "\n",
    "# Path ke direktori dataset\n",
    "dataset_dir = '../data_ori/Ori_byPhiard/train'\n",
    "output_dir = '../data_pre/keras_aug_v10'\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Membuat folder baru untuk menyimpan hasil augmentasi\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Loop melalui setiap kelas dalam dataset\n",
    "for class_name in os.listdir(dataset_dir):\n",
    "    class_path = os.path.join(dataset_dir, class_name)\n",
    "\n",
    "    # Membuat folder baru untuk setiap kelas di dalam folder output\n",
    "    output_class_path = os.path.join(output_dir, class_name)\n",
    "    if not os.path.exists(output_class_path):\n",
    "        os.makedirs(output_class_path)\n",
    "\n",
    "    # Mendapatkan list file gambar di setiap kelas\n",
    "    image_files = [os.path.join(class_path, file) for file in os.listdir(class_path) if file.endswith(('jpg', 'jpeg', 'png'))]\n",
    "\n",
    "    # Loop melalui setiap file gambar dan augmentasi datanya\n",
    "    for img_path in image_files:\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = x.reshape((1,) + x.shape)\n",
    "\n",
    "        # Menghasilkan 5 augmented images per gambar\n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size=1, save_to_dir=output_class_path,\n",
    "                                  save_prefix=os.path.splitext(os.path.basename(img_path))[0] + '_aug', save_format='png'):\n",
    "            i += 1\n",
    "            if i >= 650:  \n",
    "                break\n",
    "        break\n",
    "            \n",
    "print(f\"\\nAugmentasi Selesai!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ccb7e40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelas ba: 635 gambar\n",
      "Kelas ca: 633 gambar\n",
      "Kelas da: 632 gambar\n",
      "Kelas dha: 628 gambar\n",
      "Kelas ga: 631 gambar\n",
      "Kelas ha: 634 gambar\n",
      "Kelas ja: 632 gambar\n",
      "Kelas ka: 637 gambar\n",
      "Kelas la: 626 gambar\n",
      "Kelas ma: 630 gambar\n",
      "Kelas na: 625 gambar\n",
      "Kelas nga: 624 gambar\n",
      "Kelas nya: 626 gambar\n",
      "Kelas pa: 633 gambar\n",
      "Kelas ra: 632 gambar\n",
      "Kelas sa: 632 gambar\n",
      "Kelas ta: 633 gambar\n",
      "Kelas tha: 629 gambar\n",
      "Kelas wa: 625 gambar\n",
      "Kelas ya: 624 gambar\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "\n",
    "# output_dir = './keras_aug'\n",
    "\n",
    "# Dictionary untuk menyimpan jumlah data di setiap kelas\n",
    "kelas_data_count = {}\n",
    "\n",
    "# Loop melalui setiap kelas di dalam folder output\n",
    "for class_name in os.listdir(output_dir):\n",
    "    class_path = os.path.join(output_dir, class_name)\n",
    "    \n",
    "    # Menghitung jumlah file gambar di setiap kelas\n",
    "    num_images = len([file for file in os.listdir(class_path) if file.endswith(('jpg', 'jpeg', 'png'))])\n",
    "    \n",
    "    # Menyimpan jumlah data di setiap kelas ke dalam dictionary\n",
    "    kelas_data_count[class_name] = num_images\n",
    "\n",
    "# Menampilkan jumlah data di setiap kelas\n",
    "for class_name, count in kelas_data_count.items():\n",
    "    print(f\"Kelas {class_name}: {count} gambar\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8c907f-3945-4c92-bf48-db4936c267bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Mengatasi Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "742aee4d-71de-40bf-9a7d-faf700b07f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aksara ba jumlah: 750\n",
      "Aksara ca jumlah: 750\n",
      "Aksara da jumlah: 750\n",
      "Aksara dha jumlah: 750\n",
      "Aksara ga jumlah: 750\n",
      "Aksara ha jumlah: 750\n",
      "Aksara ja jumlah: 750\n",
      "Aksara ka jumlah: 750\n",
      "Aksara la jumlah: 750\n",
      "Aksara ma jumlah: 750\n",
      "Aksara na jumlah: 750\n",
      "Aksara nga jumlah: 750\n",
      "Aksara nya jumlah: 750\n",
      "Aksara pa jumlah: 750\n",
      "Aksara ra jumlah: 750\n",
      "Aksara sa jumlah: 750\n",
      "Aksara ta jumlah: 750\n",
      "Aksara tha jumlah: 750\n",
      "Aksara wa jumlah: 750\n",
      "Aksara ya jumlah: 750\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import random\n",
    "import string\n",
    "import os\n",
    "\n",
    "# Path dataset\n",
    "data = './aug_data'\n",
    "\n",
    "# List kelas\n",
    "kelas_aksara = ['ba', 'ca', 'da', 'dha', 'ga', 'ha', 'ja', 'ka', 'la', 'ma', 'na', 'nga', 'nya', 'pa', 'ra', 'sa', 'ta', 'tha', 'wa', 'ya']\n",
    "\n",
    "# Target jumlah gambar per kelas\n",
    "target_jumlah = 750\n",
    "\n",
    "# Loop untuk setiap kelas\n",
    "for kelas in kelas_aksara:\n",
    "    # Path kelas\n",
    "    kelas_path = os.path.join(data, kelas)\n",
    "    \n",
    "    # Jumlah gambar saat ini\n",
    "    jumlah_gambar = len(os.listdir(kelas_path))\n",
    "    \n",
    "    # Selisih gambar yang perlu ditambahkan\n",
    "    selisih = target_jumlah - jumlah_gambar\n",
    "    \n",
    "    # Jika selisih positif, lakukan oversampling\n",
    "    if selisih > 0:\n",
    "        # Ambil sampel acak dari gambar yang sudah ada\n",
    "        gambar_oversampling = random.sample(os.listdir(kelas_path), selisih)\n",
    "        \n",
    "        # Copy gambar oversampling ke dalam kelas\n",
    "        for gambar in gambar_oversampling:\n",
    "            source_path = os.path.join(kelas_path, gambar)\n",
    "            \n",
    "            # Generate sufiks acak\n",
    "            sufiks_acak = ''.join(random.choices(string.ascii_letters + string.digits, k=8))\n",
    "            \n",
    "            # Tentukan path tujuan dengan menambahkan sufiks acak\n",
    "            target_path = os.path.join(kelas_path, f'{os.path.splitext(gambar)[0]}_{sufiks_acak}{os.path.splitext(gambar)[1]}')\n",
    "            \n",
    "            # Salin gambar ke target path\n",
    "            shutil.copy(source_path, target_path)\n",
    "\n",
    "# Cetak ulang jumlah gambar per kelas setelah penyamaan\n",
    "for kelas in kelas_aksara:\n",
    "    kelas_path = os.path.join(data, kelas)\n",
    "    jumlah_gambar = len(os.listdir(kelas_path))\n",
    "    print(f'Aksara {kelas} jumlah: {jumlah_gambar}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff735589-074f-44af-9f5d-0a84a2675a48",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf3e7e7-60e2-4de8-8da2-7b4740f49ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Path ke direktori utama yang berisi sub-direktori untuk masing-masing kelas\n",
    "main_data_dir = './aug_data'\n",
    "\n",
    "# Path ke direktori output untuk train, val, dan test set\n",
    "output_dir = './data_split'\n",
    "\n",
    "# Membuat sub-direktori train, val, dan test\n",
    "train_dir = os.path.join(output_dir, 'train')\n",
    "val_dir = os.path.join(output_dir, 'val')\n",
    "test_dir = os.path.join(output_dir, 'test')\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Loop melalui masing-masing kelas (diasumsikan ada 20 kelas)\n",
    "for class_name in os.listdir(main_data_dir):\n",
    "    class_path = os.path.join(main_data_dir, class_name)\n",
    "    \n",
    "    # Mendapatkan list file untuk kelas tertentu\n",
    "    files = os.listdir(class_path)\n",
    "    \n",
    "    # Membagi data menjadi train, val, dan test set\n",
    "    train_files, temp_files = train_test_split(files, test_size=0.3, random_state=42)\n",
    "    val_files, test_files = train_test_split(temp_files, test_size=0.33, random_state=42)\n",
    "    \n",
    "    # Membuat sub-direktori untuk masing-masing kelas di train, val, dan test set\n",
    "    train_class_dir = os.path.join(train_dir, class_name)\n",
    "    val_class_dir = os.path.join(val_dir, class_name)\n",
    "    test_class_dir = os.path.join(test_dir, class_name)\n",
    "    \n",
    "    os.makedirs(train_class_dir, exist_ok=True)\n",
    "    os.makedirs(val_class_dir, exist_ok=True)\n",
    "    os.makedirs(test_class_dir, exist_ok=True)\n",
    "    \n",
    "    # Menyalin file ke dalam masing-masing sub-direktori\n",
    "    for file in train_files:\n",
    "        shutil.copy(os.path.join(class_path, file), os.path.join(train_class_dir, file))\n",
    "    \n",
    "    for file in val_files:\n",
    "        shutil.copy(os.path.join(class_path, file), os.path.join(val_class_dir, file))\n",
    "    \n",
    "    for file in test_files:\n",
    "        shutil.copy(os.path.join(class_path, file), os.path.join(test_class_dir, file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
