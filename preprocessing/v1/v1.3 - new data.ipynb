{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percobaan ke-1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasil Augmentasi di campur di setiap kelas nya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# # Fungsi untuk membaca file CSV dengan bounding box\n",
    "# def read_csv(csv_file):\n",
    "#     return pd.read_csv(csv_file)\n",
    "\n",
    "# # Fungsi untuk menyimpan label ke dalam file CSV\n",
    "# def save_to_csv(labels, csv_file):\n",
    "#     df = pd.DataFrame(labels, columns=['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
    "#     df.to_csv(csv_file, index=False)\n",
    "\n",
    "# # Lokasi direktori dataset asli\n",
    "# original_dataset_dir = '../data/data_original/Pengenalan Aksara Jawa-tensorflow/train/'\n",
    "\n",
    "# # Lokasi direktori untuk menyimpan gambar hasil augmentasi\n",
    "# augmented_dataset_dir = '../data/data_preprocessing/v1.1'\n",
    "\n",
    "# # Buat direktori jika belum ada\n",
    "# os.makedirs(augmented_dataset_dir, exist_ok=True)\n",
    "\n",
    "# # Baca file CSV dengan bounding box\n",
    "# original_csv_file = os.path.join(original_dataset_dir, '_annotations.csv')\n",
    "# labels = read_csv(original_csv_file)\n",
    "\n",
    "# # Inisialisasi ImageDataGenerator untuk augmentasi gambar\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=19,\n",
    "#     width_shift_range=None,\n",
    "#     height_shift_range=None,\n",
    "#     shear_range=0.1,\n",
    "#     zoom_range=0.1,\n",
    "#     horizontal_flip=False,  \n",
    "#     fill_mode='nearest'\n",
    "# )\n",
    "\n",
    "# # Augmentasi dan simpan gambar serta label ke dalam file CSV\n",
    "# augmented_labels = []\n",
    "\n",
    "# for index, row in labels.iterrows():\n",
    "#     image_path = os.path.join(original_dataset_dir, row['filename'])\n",
    "#     img = image.load_img(image_path)\n",
    "#     x = image.img_to_array(img)\n",
    "#     x = np.expand_dims(x, axis=0)\n",
    "\n",
    "#     # Generate augmentasi gambar sebanyak 500 kali\n",
    "#     i = 0\n",
    "#     for batch in datagen.flow(x, batch_size=1):\n",
    "#         augmented_image = batch[0].astype('uint8')\n",
    "\n",
    "#         augmented_filename = f\"{os.path.splitext(row['filename'])[0]}_aug_{i}.jpg\"\n",
    "#         augmented_image_path = os.path.join(augmented_dataset_dir, augmented_filename)\n",
    "\n",
    "#         # Simpan gambar hasil augmentasi\n",
    "#         image.save_img(augmented_image_path, augmented_image)\n",
    "\n",
    "#         # Update label dengan informasi gambar hasil augmentasi\n",
    "#         augmented_labels.append([\n",
    "#             augmented_filename,\n",
    "#             row['width'],\n",
    "#             row['height'],\n",
    "#             row['class'],\n",
    "#             row['xmin'],\n",
    "#             row['ymin'],\n",
    "#             row['xmax'],\n",
    "#             row['ymax']\n",
    "#         ])\n",
    "\n",
    "#         i += 1\n",
    "#         if i >= 5:\n",
    "#             break\n",
    "\n",
    "# # Simpan label hasil augmentasi ke dalam file CSV baru\n",
    "# augmented_csv_file = os.path.join(augmented_dataset_dir, 'augmented_labels.csv')\n",
    "# save_to_csv(augmented_labels, augmented_csv_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percobaan ke-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasil Augmentasi di buatkan sub folder tapi ukuran images masih mengikuti yang lama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 55\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Main path and categories\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# main_path = '../data/data_original/Pengenalan Aksara Jawa-tensorflow/train/'\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# aksara_categories = ['category1', 'category2', 'category3']  # Modify with actual category names\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# image_size = (64, 64)\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Load images with Laplacian of Gaussian filter applied\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m X, y \u001b[38;5;241m=\u001b[39m load_images(\u001b[43mmain_path\u001b[49m, aksara_categories, image_size)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Select one image to display\u001b[39;00m\n\u001b[0;32m     58\u001b[0m index_to_display \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'main_path' is not defined"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from keras.utils import to_categorical\n",
    "# from PIL import Image\n",
    "\n",
    "# def apply_laplacian_of_gaussian(image, size, sigma):\n",
    "#     # Convert image to uint8\n",
    "#     image_uint8 = (image * 255).astype(np.uint8)\n",
    "    \n",
    "#     # Apply Gaussian filter\n",
    "#     gaussian_filtered = cv2.GaussianBlur(image_uint8, (size, size), sigma)\n",
    "    \n",
    "#     # Apply Laplacian filter\n",
    "#     laplacian_filtered = cv2.Laplacian(gaussian_filtered, cv2.CV_64F)\n",
    "    \n",
    "#     return laplacian_filtered\n",
    "\n",
    "# def create_image_generator_with_log(main_path, emotions, image_size):\n",
    "#     for index, emotion in enumerate(emotions):\n",
    "#         emotion_path = os.path.join(main_path, emotion)\n",
    "#         for filename in os.listdir(emotion_path):\n",
    "#             image_path = os.path.join(emotion_path, filename)\n",
    "#             image = cv2.imread(image_path)\n",
    "#             image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "#             image = cv2.resize(image, image_size)  # Resize image\n",
    "            \n",
    "#             # Normalization\n",
    "#             image = image.astype('float32') / 255.0\n",
    "            \n",
    "#             # Apply Laplacian of Gaussian filter\n",
    "#             image_filtered = apply_laplacian_of_gaussian(image, size=3, sigma=1.0)\n",
    "            \n",
    "#             yield image, image_filtered, index\n",
    "\n",
    "# def load_images(main_path, emotions, image_size):\n",
    "#     X, y = [], []\n",
    "    \n",
    "#     for image, image_filtered, label in create_image_generator_with_log(main_path, emotions, image_size):\n",
    "#         X.append(image_filtered)\n",
    "#         y.append(label)\n",
    "    \n",
    "#     X = np.array(X)\n",
    "#     y = to_categorical(np.array(y))\n",
    "    \n",
    "#     return X, y\n",
    "\n",
    "# # Main path and categories\n",
    "# main_path = '../data/data_original/Pengenalan Aksara Jawa-tensorflow/train/'\n",
    "# aksara_categories = ['category1', 'category2', 'category3']  # Modify with actual category names\n",
    "# image_size = (64, 64)\n",
    "\n",
    "# # Load images with Laplacian of Gaussian filter applied\n",
    "# X, y = load_images(main_path, aksara_categories, image_size)\n",
    "\n",
    "# # Select one image to display\n",
    "# index_to_display = 0\n",
    "\n",
    "# # Retrieve the original grayscale image and its corresponding filtered image\n",
    "# generator = create_image_generator_with_log(main_path, aksara_categories, image_size)\n",
    "# for i, (original_image, filtered_image, _) in enumerate(generator):\n",
    "#     if i == index_to_display:\n",
    "#         sample_image_original = original_image\n",
    "#         sample_image_filtered = filtered_image\n",
    "#         break\n",
    "\n",
    "# # Apply thresholding for edge detection results\n",
    "# threshold = 5\n",
    "# sample_image_filtered_thresholded = np.zeros_like(sample_image_filtered)\n",
    "# sample_image_filtered_thresholded[sample_image_filtered > threshold] = 255\n",
    "\n",
    "# # Display the original image, grayscale image, and filtered image\n",
    "# plt.figure(figsize=(12, 4))\n",
    "\n",
    "# plt.subplot(1, 3, 1)\n",
    "# plt.imshow(Image.fromarray((sample_image_original * 255).astype(np.uint8), 'L'), cmap='gray')\n",
    "# plt.title(\"Grayscale Image\")\n",
    "\n",
    "# plt.subplot(1, 3, 2)\n",
    "# plt.imshow((sample_image_original * 255).astype(np.uint8), cmap='gray')\n",
    "# plt.title(\"Original Image\")\n",
    "\n",
    "# plt.subplot(1, 3, 3)\n",
    "# plt.imshow(sample_image_filtered_thresholded, cmap='gray')\n",
    "# plt.title(\"Filtered Image (LoG + Threshold)\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# from PIL import Image\n",
    "\n",
    "# # Fungsi untuk membaca file CSV dengan bounding box\n",
    "# def read_csv(csv_file):\n",
    "#     return pd.read_csv(csv_file)\n",
    "\n",
    "# # Fungsi untuk menyimpan label ke dalam file CSV\n",
    "# def save_to_csv(labels, csv_file):\n",
    "#     df = pd.DataFrame(labels, columns=['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
    "#     df.to_csv(csv_file, index=False)\n",
    "\n",
    "# # Lokasi direktori dataset asli\n",
    "# original_dataset_dir = '../data/data_original/Pengenalan Aksara Jawa-tensorflow/train/'\n",
    "\n",
    "# # Lokasi direktori untuk menyimpan gambar hasil augmentasi\n",
    "# augmented_dataset_dir = '../data/data_preprocessing/v1.2'\n",
    "\n",
    "# # Buat direktori jika belum ada\n",
    "# os.makedirs(augmented_dataset_dir, exist_ok=True)\n",
    "\n",
    "# # Baca file CSV dengan bounding box\n",
    "# original_csv_file = os.path.join(original_dataset_dir, '_annotations.csv')\n",
    "# labels = read_csv(original_csv_file)\n",
    "\n",
    "# # Inisialisasi ImageDataGenerator untuk augmentasi gambar\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=19,\n",
    "#     width_shift_range=None,\n",
    "#     height_shift_range=None,\n",
    "#     shear_range=0.1,\n",
    "#     zoom_range=0.1,\n",
    "#     horizontal_flip=False,  \n",
    "#     fill_mode='nearest'\n",
    "# )\n",
    "\n",
    "# # Augmentasi dan simpan gambar serta label ke dalam file CSV\n",
    "# augmented_labels = []\n",
    "\n",
    "# for index, row in labels.iterrows():\n",
    "#     image_path = os.path.join(original_dataset_dir, row['filename'])\n",
    "#     img = image.load_img(image_path, target_size=(96, 96))  # Mengatur ukuran gambar\n",
    "#     x = image.img_to_array(img)\n",
    "#     x = np.expand_dims(x, axis=0)\n",
    "\n",
    "#     # Buat subfolder untuk setiap kelas jika belum ada\n",
    "#     class_folder = os.path.join(augmented_dataset_dir, row['class'])\n",
    "#     os.makedirs(class_folder, exist_ok=True)\n",
    "\n",
    "#     # Generate augmentasi gambar sebanyak 2 kali\n",
    "#     for i, batch in enumerate(datagen.flow(x, batch_size=1)):\n",
    "#         augmented_image = batch[0].astype('uint8')\n",
    "\n",
    "#         augmented_filename = f\"{os.path.splitext(row['filename'])[0]}_aug_{i}.png\"\n",
    "#         augmented_image_path = os.path.join(class_folder, augmented_filename)\n",
    "\n",
    "#         # Simpan gambar hasil augmentasi\n",
    "#         augmented_image = Image.fromarray(augmented_image)\n",
    "#         augmented_image.save(augmented_image_path)\n",
    "\n",
    "#         # Update label dengan informasi gambar hasil augmentasi\n",
    "#         augmented_labels.append([\n",
    "#             augmented_filename,\n",
    "#             row['width'],\n",
    "#             row['height'],\n",
    "#             row['class'],\n",
    "#             row['xmin'],\n",
    "#             row['ymin'],\n",
    "#             row['xmax'],\n",
    "#             row['ymax']\n",
    "#         ])\n",
    "\n",
    "#         if i >= 5:  # Ubah jumlah augmentasi sesuai kebutuhan\n",
    "#             break\n",
    "\n",
    "# # Simpan label hasil augmentasi ke dalam file CSV baru\n",
    "# augmented_csv_file = os.path.join(augmented_dataset_dir, 'augmented_labels.csv')\n",
    "# save_to_csv(augmented_labels, augmented_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cetak Jumlah images/kelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelas Ba: 48 gambar\n",
      "Kelas Ca: 36 gambar\n",
      "Kelas Da: 48 gambar\n",
      "Kelas Dha: 48 gambar\n",
      "Kelas Ga: 48 gambar\n",
      "Kelas Ha: 54 gambar\n",
      "Kelas Ja: 42 gambar\n",
      "Kelas Ka: 42 gambar\n",
      "Kelas La: 48 gambar\n",
      "Kelas Ma: 36 gambar\n",
      "Kelas Na: 42 gambar\n",
      "Kelas Nga: 30 gambar\n",
      "Kelas Nya: 18 gambar\n",
      "Kelas Pa: 36 gambar\n",
      "Kelas Ra: 54 gambar\n",
      "Kelas Sa: 42 gambar\n",
      "Kelas Ta: 42 gambar\n",
      "Kelas Tha: 42 gambar\n",
      "Kelas Wa: 48 gambar\n",
      "Kelas Ya: 36 gambar\n"
     ]
    }
   ],
   "source": [
    "# # Lokasi direktori dataset asli\n",
    "# augmented_dataset_dir = augmented_dataset_dir\n",
    "\n",
    "# # Daftar kelas (nama subfolder)\n",
    "# classes = os.listdir(augmented_dataset_dir)\n",
    "\n",
    "# # Dictionary untuk menyimpan jumlah gambar dalam setiap kelas\n",
    "# class_counts = {}\n",
    "\n",
    "# # Iterasi melalui setiap kelas\n",
    "# for class_name in classes:\n",
    "#     class_folder = os.path.join(augmented_dataset_dir, class_name)\n",
    "#     if os.path.isdir(class_folder):\n",
    "#         # Hitung jumlah file gambar dalam subfolder (kelas)\n",
    "#         num_images = len([name for name in os.listdir(class_folder) if os.path.isfile(os.path.join(class_folder, name))])\n",
    "#         class_counts[class_name] = num_images\n",
    "\n",
    "# # Tampilkan jumlah gambar dalam setiap kelas\n",
    "# for class_name, count in class_counts.items():\n",
    "#     print(f\"Kelas {class_name}: {count} gambar\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced Dataset with Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m original_label_index \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m%\u001b[39m count\n\u001b[0;32m     33\u001b[0m new_label_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_copy_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 34\u001b[0m original_label \u001b[38;5;241m=\u001b[39m \u001b[43maugmented_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43moriginal_label_index\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Dapatkan entri label asli\u001b[39;00m\n\u001b[0;32m     35\u001b[0m new_label \u001b[38;5;241m=\u001b[39m original_label[:]  \u001b[38;5;66;03m# Salin entri label\u001b[39;00m\n\u001b[0;32m     36\u001b[0m new_label[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m new_label_filename  \u001b[38;5;66;03m# Perbarui nama file gambar\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# # Hitung jumlah gambar di setiap kelas\n",
    "# class_counts = labels['class'].value_counts().to_dict()\n",
    "\n",
    "# # Temukan kelas dengan jumlah gambar terbanyak\n",
    "# max_images = max(class_counts.values())\n",
    "# max_class = max(class_counts, key=class_counts.get)\n",
    "\n",
    "# # Augmentasi dan simpan gambar serta label ke dalam file CSV\n",
    "# augmented_labels = []\n",
    "\n",
    "# # Iterasi melalui setiap kelas\n",
    "# for class_name, count in class_counts.items():\n",
    "#     class_folder = os.path.join(augmented_dataset_dir, class_name)\n",
    "#     if os.path.isdir(class_folder) and class_name != max_class:\n",
    "#         # Hitung selisih jumlah gambar dengan kelas yang memiliki jumlah terbanyak\n",
    "#         num_images_to_add = max_images - count\n",
    "        \n",
    "#         # Buat salinan data pada kelas yang memiliki jumlah gambar lebih sedikit\n",
    "#         if num_images_to_add > 0:\n",
    "#             images = os.listdir(class_folder)\n",
    "#             for i in range(num_images_to_add):\n",
    "#                 # Salin gambar ke dalam kelas yang sedang diproses\n",
    "#                 source_image = os.path.join(class_folder, images[i % count])\n",
    "#                 base_filename = os.path.splitext(images[i % count])[0]  # Ambil nama file asli tanpa ekstensi\n",
    "#                 dest_image = os.path.join(class_folder, f\"{base_filename}_copy_{i+1}.png\")\n",
    "#                 shutil.copy(source_image, dest_image)\n",
    "                \n",
    "#                 # Update jumlah gambar di kelas yang sedang diproses\n",
    "#                 class_counts[class_name] += 1\n",
    "                \n",
    "#                 # Salin entri label\n",
    "#                 original_label_index = i % count\n",
    "#                 new_label_filename = f\"{base_filename}_copy_{i+1}.png\"\n",
    "#                 original_label = augmented_labels[original_label_index]  # Dapatkan entri label asli\n",
    "#                 new_label = original_label[:]  # Salin entri label\n",
    "#                 new_label[0] = new_label_filename  # Perbarui nama file gambar\n",
    "#                 augmented_labels.append(new_label)  # Tambahkan entri label baru\n",
    "\n",
    "# # Simpan label hasil augmentasi ke dalam file CSV baru setelah oversampling\n",
    "# augmented_csv_file = os.path.join(augmented_dataset_dir, 'augmented_labels.csv')\n",
    "# save_to_csv(augmented_labels, augmented_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percobaan ke-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sudah di buatkan subfolder tapi hasil augmentasi kurang akurat, follow untuk data imbalenced data nya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data bounding box yang telah diubah telah disimpan ke CSV baru dan gambar disimpan ke subfolder berdasarkan kelas.\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# import os\n",
    "\n",
    "# def adjust_bounding_box(bbox, original_size, new_size, flip_h=False, flip_v=False):\n",
    "#     xmin, ymin, xmax, ymax = bbox\n",
    "#     orig_w, orig_h = original_size\n",
    "#     new_w, new_h = new_size\n",
    "\n",
    "#     scale_x = new_w / orig_w\n",
    "#     scale_y = new_h / orig_h\n",
    "\n",
    "#     xmin_new = xmin * scale_x\n",
    "#     ymin_new = ymin * scale_y\n",
    "#     xmax_new = xmax * scale_x\n",
    "#     ymax_new = ymax * scale_y\n",
    "\n",
    "#     if flip_h:\n",
    "#         xmin_new, xmax_new = new_w - xmax_new, new_w - xmin_new\n",
    "\n",
    "#     if flip_v:\n",
    "#         ymin_new, ymax_new = new_h - ymax_new, new_h - ymin_new\n",
    "\n",
    "#     return xmin_new, ymin_new, xmax_new, ymax_new\n",
    "\n",
    "# def make_directory(path):\n",
    "#     if not os.path.exists(path):\n",
    "#         os.makedirs(path)\n",
    "\n",
    "# # Baca data dari CSV lama\n",
    "# df = pd.read_csv(\"../data/data_original/Pengenalan Aksara Jawa-tensorflow/train/_annotations.csv\")\n",
    "\n",
    "# # Daftar untuk menyimpan data yang telah diubah\n",
    "# new_data = []\n",
    "\n",
    "# # Direktori untuk menyimpan gambar dan label hasil augmentasi\n",
    "# original_dir = \"../data/data_original/Pengenalan Aksara Jawa-tensorflow/train/\"\n",
    "# augmented_path = \"../data/data_preprocessing/v1.2/\"\n",
    "# augmented_label_path = \"../data/data_preprocessing/v1.2/augmented_labels.csv\"\n",
    "# make_directory(augmented_path)\n",
    "\n",
    "# # ImageDataGenerator untuk augmentasi\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=19,\n",
    "#     width_shift_range=None,\n",
    "#     height_shift_range=None,\n",
    "#     shear_range=0.1,\n",
    "#     zoom_range=0.1,\n",
    "#     horizontal_flip=False,\n",
    "#     vertical_flip=False,\n",
    "#     fill_mode='nearest'\n",
    "# )\n",
    "\n",
    "# # Tentukan ukuran baru (misalnya, 256x256)\n",
    "# new_width, new_height = 96, 96\n",
    "\n",
    "# # Augmentasi setiap kelas sebanyak 100 kali\n",
    "# for class_name in df['class'].unique():\n",
    "#     class_df = df[df['class'] == class_name]\n",
    "    \n",
    "#     # Buat subfolder untuk kelas ini\n",
    "#     class_dir = os.path.join(augmented_path, class_name)\n",
    "#     make_directory(class_dir)\n",
    "    \n",
    "#     for i in range(30):\n",
    "#         for index, row in class_df.iterrows():\n",
    "#             filename = row['filename']\n",
    "#             orig_width = row['width']\n",
    "#             orig_height = row['height']\n",
    "#             class_name = row['class']\n",
    "#             xmin = row['xmin']\n",
    "#             ymin = row['ymin']\n",
    "#             xmax = row['xmax']\n",
    "#             ymax = row['ymax']\n",
    "\n",
    "#             image_path = os.path.join(original_dir, filename)\n",
    "#             image = cv2.imread(image_path)\n",
    "#             original_size = (orig_width, orig_height)\n",
    "\n",
    "#             # Convert image to array and expand dimensions\n",
    "#             image_array = np.expand_dims(image, 0)\n",
    "\n",
    "#             # Augmentasi gambar\n",
    "#             for batch in datagen.flow(image_array, batch_size=1):\n",
    "#                 aug_image = batch[0].astype('uint8')\n",
    "\n",
    "#                 # Resize image\n",
    "#                 aug_image_resized = cv2.resize(aug_image, (new_width, new_height))\n",
    "\n",
    "#                 # Adjust bounding box\n",
    "#                 flip_h = 'horizontal_flip' in datagen.__dict__ and datagen.horizontal_flip\n",
    "#                 flip_v = 'vertical_flip' in datagen.__dict__ and datagen.vertical_flip\n",
    "#                 new_bbox = adjust_bounding_box((xmin, ymin, xmax, ymax), original_size, (new_width, new_height), flip_h, flip_v)\n",
    "\n",
    "#                 # Simpan gambar yang telah diubah\n",
    "#                 aug_filename = f'{filename.split(\".\")[0]}_aug_{i}_{index}.png'\n",
    "#                 aug_image_path = os.path.join(class_dir, aug_filename)\n",
    "#                 cv2.imwrite(aug_image_path, aug_image_resized)\n",
    "\n",
    "#                 # Tambahkan data baru ke daftar\n",
    "#                 new_data.append([aug_filename, new_width, new_height, class_name, *new_bbox])\n",
    "\n",
    "#                 break  # hanya menghasilkan satu augmentasi per gambar per iterasi\n",
    "\n",
    "# # Membuat DataFrame baru dari data yang telah diubah\n",
    "# new_df = pd.DataFrame(new_data, columns=['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
    "\n",
    "# # Menyimpan DataFrame ke CSV baru\n",
    "# new_df.to_csv(augmented_label_path, index=False)\n",
    "\n",
    "# print(\"Data bounding box yang telah diubah telah disimpan ke CSV baru dan gambar disimpan ke subfolder berdasarkan kelas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelas Ba: 242 gambar\n",
      "Kelas Ca: 180 gambar\n",
      "Kelas Da: 240 gambar\n",
      "Kelas Dha: 240 gambar\n",
      "Kelas Ga: 240 gambar\n",
      "Kelas Ha: 270 gambar\n",
      "Kelas Ja: 210 gambar\n",
      "Kelas Ka: 210 gambar\n",
      "Kelas La: 240 gambar\n",
      "Kelas Ma: 180 gambar\n",
      "Kelas Na: 210 gambar\n",
      "Kelas Nga: 150 gambar\n",
      "Kelas Nya: 90 gambar\n",
      "Kelas Pa: 180 gambar\n",
      "Kelas Ra: 270 gambar\n",
      "Kelas Sa: 210 gambar\n",
      "Kelas Ta: 210 gambar\n",
      "Kelas Tha: 210 gambar\n",
      "Kelas Wa: 240 gambar\n",
      "Kelas Ya: 180 gambar\n"
     ]
    }
   ],
   "source": [
    "# # Lokasi direktori dataset asli\n",
    "# dataset_path = augmented_path\n",
    "\n",
    "# # Daftar kelas (nama subfolder)\n",
    "# classes = os.listdir(dataset_path)\n",
    "\n",
    "# # Dictionary untuk menyimpan jumlah gambar dalam setiap kelas\n",
    "# class_counts = {}\n",
    "\n",
    "# # Iterasi melalui setiap kelas\n",
    "# for class_name in classes:\n",
    "#     class_folder = os.path.join(dataset_path, class_name)\n",
    "#     if os.path.isdir(class_folder):\n",
    "#         # Hitung jumlah file gambar dalam subfolder (kelas)\n",
    "#         num_images = len([name for name in os.listdir(class_folder) if os.path.isfile(os.path.join(class_folder, name))])\n",
    "#         class_counts[class_name] = num_images\n",
    "\n",
    "# # Tampilkan jumlah gambar dalam setiap kelas\n",
    "# for class_name, count in class_counts.items():\n",
    "#     print(f\"Kelas {class_name}: {count} gambar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percobaan ke-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rekomendasi - Hasil Augmentasi mendekati jumlah sesuai keinginan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data bounding box yang telah diubah telah disimpan ke CSV baru dan gambar disimpan ke subfolder berdasarkan kelas.\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# import os\n",
    "\n",
    "# def adjust_bounding_box(bbox, original_size, new_size, flip_h=False, flip_v=False):\n",
    "#     xmin, ymin, xmax, ymax = bbox\n",
    "#     orig_w, orig_h = original_size\n",
    "#     new_w, new_h = new_size\n",
    "\n",
    "#     scale_x = new_w / orig_w\n",
    "#     scale_y = new_h / orig_h\n",
    "\n",
    "#     xmin_new = xmin * scale_x\n",
    "#     ymin_new = ymin * scale_y\n",
    "#     xmax_new = xmax * scale_x\n",
    "#     ymax_new = ymax * scale_y\n",
    "\n",
    "#     if flip_h:\n",
    "#         xmin_new, xmax_new = new_w - xmax_new, new_w - xmin_new\n",
    "\n",
    "#     if flip_v:\n",
    "#         ymin_new, ymax_new = new_h - ymax_new, new_h - ymin_new\n",
    "\n",
    "#     return xmin_new, ymin_new, xmax_new, ymax_new\n",
    "\n",
    "# def make_directory(path):\n",
    "#     if not os.path.exists(path):\n",
    "#         os.makedirs(path)\n",
    "\n",
    "# # Baca data dari CSV lama\n",
    "# df = pd.read_csv(\"../data/data_original/Pengenalan Aksara Jawa-tensorflow/train/_annotations.csv\")\n",
    "\n",
    "# # Daftar untuk menyimpan data yang telah diubah\n",
    "# new_data = []\n",
    "\n",
    "# # Direktori untuk menyimpan gambar dan label hasil augmentasi\n",
    "# original_image_dir = \"../data/data_original/Pengenalan Aksara Jawa-tensorflow/train/\"\n",
    "# augmented_image_dir = \"../data/data_preprocessing/v1.5/\"\n",
    "# augmented_label_file = \"../data/data_preprocessing/v1.5/augmented_labels.csv\"\n",
    "# make_directory(augmented_image_dir)\n",
    "\n",
    "# # ImageDataGenerator untuk augmentasi\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=19,\n",
    "#     width_shift_range=None,\n",
    "#     height_shift_range=None,\n",
    "#     shear_range=0.1,\n",
    "#     zoom_range=0.1,\n",
    "#     horizontal_flip=False,\n",
    "#     vertical_flip=False,\n",
    "#     fill_mode='nearest'\n",
    "# )\n",
    "\n",
    "# # Tentukan ukuran baru (misalnya, 96x96)\n",
    "# new_width, new_height = 96, 96\n",
    "\n",
    "# # Augmentasi setiap kelas sebanyak 5 kali\n",
    "# for class_name in df['class'].unique():\n",
    "#     class_df = df[df['class'] == class_name]\n",
    "    \n",
    "#     # Buat subfolder untuk kelas ini\n",
    "#     class_dir = os.path.join(augmented_image_dir, class_name)\n",
    "#     make_directory(class_dir)\n",
    "    \n",
    "#     augment_count = 0  # Tambahkan counter untuk menghitung jumlah augmentasi per kelas\n",
    "    \n",
    "#     for index, row in class_df.iterrows():\n",
    "#         if augment_count >= 5:\n",
    "#             break\n",
    "        \n",
    "#         filename = row['filename']\n",
    "#         orig_width = row['width']\n",
    "#         orig_height = row['height']\n",
    "#         class_name = row['class']\n",
    "#         xmin = row['xmin']\n",
    "#         ymin = row['ymin']\n",
    "#         xmax = row['xmax']\n",
    "#         ymax = row['ymax']\n",
    "\n",
    "#         image_path = os.path.join(original_image_dir, filename)\n",
    "#         image = cv2.imread(image_path)\n",
    "#         original_size = (orig_width, orig_height)\n",
    "\n",
    "#         # Convert image to array and expand dimensions\n",
    "#         image_array = np.expand_dims(image, 0)\n",
    "\n",
    "#         # Augmentasi gambar\n",
    "#         for batch in datagen.flow(image_array, batch_size=1):\n",
    "#             aug_image = batch[0].astype('uint8')\n",
    "\n",
    "#             # Resize image\n",
    "#             aug_image_resized = cv2.resize(aug_image, (new_width, new_height))\n",
    "\n",
    "#             # Adjust bounding box\n",
    "#             flip_h = 'horizontal_flip' in datagen.__dict__ and datagen.horizontal_flip\n",
    "#             flip_v = 'vertical_flip' in datagen.__dict__ and datagen.vertical_flip\n",
    "#             new_bbox = adjust_bounding_box((xmin, ymin, xmax, ymax), original_size, (new_width, new_height), flip_h, flip_v)\n",
    "\n",
    "#             # Simpan gambar yang telah diubah\n",
    "#             aug_filename = f'{filename.split(\".\")[0]}_aug_{augment_count}_{index}.png'\n",
    "#             aug_image_path = os.path.join(class_dir, aug_filename)\n",
    "#             cv2.imwrite(aug_image_path, aug_image_resized)\n",
    "\n",
    "#             # Tambahkan data baru ke daftar\n",
    "#             new_data.append([aug_filename, new_width, new_height, class_name, *new_bbox])\n",
    "\n",
    "#             augment_count += 1  # Tingkatkan counter\n",
    "#             break  # hanya menghasilkan satu augmentasi per gambar per iterasi\n",
    "\n",
    "# # Membuat DataFrame baru dari data yang telah diubah\n",
    "# new_df = pd.DataFrame(new_data, columns=['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
    "\n",
    "# # Menyimpan DataFrame ke CSV baru\n",
    "# new_df.to_csv(augmented_label_file, index=False)\n",
    "\n",
    "# print(\"Data bounding box yang telah diubah telah disimpan ke CSV baru dan gambar disimpan ke subfolder berdasarkan kelas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data bounding box yang telah diubah telah disimpan ke CSV baru dan gambar disimpan ke subfolder berdasarkan kelas.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "def adjust_bounding_box(bbox, original_size, new_size, flip_h=False, flip_v=False):\n",
    "    xmin, ymin, xmax, ymax = bbox\n",
    "    orig_w, orig_h = original_size\n",
    "    new_w, new_h = new_size\n",
    "\n",
    "    scale_x = new_w / orig_w\n",
    "    scale_y = new_h / orig_h\n",
    "\n",
    "    xmin_new = xmin * scale_x\n",
    "    ymin_new = ymin * scale_y\n",
    "    xmax_new = xmax * scale_x\n",
    "    ymax_new = ymax * scale_y\n",
    "\n",
    "    if flip_h:\n",
    "        xmin_new, xmax_new = new_w - xmax_new, new_w - xmin_new\n",
    "\n",
    "    if flip_v:\n",
    "        ymin_new, ymax_new = new_h - ymax_new, new_h - ymin_new\n",
    "\n",
    "    return xmin_new, ymin_new, xmax_new, ymax_new\n",
    "\n",
    "def make_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "# Baca data dari CSV lama\n",
    "df = pd.read_csv(\"../data/data_original/Pengenalan Aksara Jawa-tensorflow/train/_annotations.csv\")\n",
    "\n",
    "# Daftar untuk menyimpan data yang telah diubah\n",
    "new_data = []\n",
    "\n",
    "# Direktori untuk menyimpan gambar dan label hasil augmentasi\n",
    "original_image_dir = \"../data/data_original/Pengenalan Aksara Jawa-tensorflow/train/\"\n",
    "augmented_image_dir = \"../data/data_preprocessing/v2.1/\"\n",
    "augmented_label_file = \"../data/data_preprocessing/v2.1/augmented_labels.csv\"\n",
    "make_directory(augmented_image_dir)\n",
    "\n",
    "# ImageDataGenerator untuk augmentasi\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=None,\n",
    "    height_shift_range=None,\n",
    "    shear_range=0.0,\n",
    "    zoom_range=0.0,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Tentukan ukuran baru (misalnya, 96x96)\n",
    "new_width, new_height = 128, 128\n",
    "\n",
    "# Augmentasi setiap kelas sebanyak 5 kali\n",
    "augmentations_per_class = 650\n",
    "\n",
    "for class_name in df['class'].unique():\n",
    "    class_df = df[df['class'] == class_name]\n",
    "    \n",
    "    # Buat subfolder untuk kelas ini\n",
    "    class_dir = os.path.join(augmented_image_dir, class_name)\n",
    "    make_directory(class_dir)\n",
    "    \n",
    "    augment_count = 0  # Tambahkan counter untuk menghitung jumlah augmentasi per kelas\n",
    "    \n",
    "    for index, row in class_df.iterrows():\n",
    "        if augment_count >= augmentations_per_class:\n",
    "            break\n",
    "        \n",
    "        filename = row['filename']\n",
    "        orig_width = row['width']\n",
    "        orig_height = row['height']\n",
    "        class_name = row['class']\n",
    "        xmin = row['xmin']\n",
    "        ymin = row['ymin']\n",
    "        xmax = row['xmax']\n",
    "        ymax = row['ymax']\n",
    "\n",
    "        image_path = os.path.join(original_image_dir, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        original_size = (orig_width, orig_height)\n",
    "\n",
    "        # Convert image to array and expand dimensions\n",
    "        image_array = np.expand_dims(image, 0)\n",
    "\n",
    "        # Augmentasi gambar\n",
    "        for batch in datagen.flow(image_array, batch_size=1):\n",
    "            aug_image = batch[0].astype('uint8')\n",
    "\n",
    "            # Resize image\n",
    "            aug_image_resized = cv2.resize(aug_image, (new_width, new_height))\n",
    "\n",
    "            # Adjust bounding box\n",
    "            flip_h = 'horizontal_flip' in datagen.__dict__ and datagen.horizontal_flip\n",
    "            flip_v = 'vertical_flip' in datagen.__dict__ and datagen.vertical_flip\n",
    "            new_bbox = adjust_bounding_box((xmin, ymin, xmax, ymax), original_size, (new_width, new_height), flip_h, flip_v)\n",
    "\n",
    "            # Simpan gambar yang telah diubah\n",
    "            aug_filename = f'{filename.split(\".\")[0]}_aug_{augment_count}.png'\n",
    "            aug_image_path = os.path.join(class_dir, aug_filename)\n",
    "            cv2.imwrite(aug_image_path, aug_image_resized)\n",
    "\n",
    "            # Tambahkan data baru ke daftar\n",
    "            new_data.append([aug_filename, new_width, new_height, class_name, *new_bbox])\n",
    "\n",
    "            augment_count += 1  # Tingkatkan counter\n",
    "            if augment_count >= augmentations_per_class:\n",
    "                break  # keluar dari loop augmentasi jika sudah cukup\n",
    "\n",
    "# Membuat DataFrame baru dari data yang telah diubah\n",
    "new_df = pd.DataFrame(new_data, columns=['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
    "\n",
    "# Menyimpan DataFrame ke CSV baru\n",
    "new_df.to_csv(augmented_label_file, index=False)\n",
    "\n",
    "print(\"Data bounding box yang telah diubah telah disimpan ke CSV baru dan gambar disimpan ke subfolder berdasarkan kelas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelas Ba: 650 gambar\n",
      "Kelas Ca: 650 gambar\n",
      "Kelas Da: 650 gambar\n",
      "Kelas Dha: 650 gambar\n",
      "Kelas Ga: 650 gambar\n",
      "Kelas Ha: 650 gambar\n",
      "Kelas Ja: 650 gambar\n",
      "Kelas Ka: 650 gambar\n",
      "Kelas La: 650 gambar\n",
      "Kelas Ma: 650 gambar\n",
      "Kelas Na: 650 gambar\n",
      "Kelas Nga: 650 gambar\n",
      "Kelas Nya: 650 gambar\n",
      "Kelas Pa: 650 gambar\n",
      "Kelas Ra: 650 gambar\n",
      "Kelas Sa: 650 gambar\n",
      "Kelas Ta: 650 gambar\n",
      "Kelas Tha: 650 gambar\n",
      "Kelas Wa: 650 gambar\n",
      "Kelas Ya: 650 gambar\n"
     ]
    }
   ],
   "source": [
    "# Lokasi direktori dataset asli\n",
    "dataset_path = augmented_image_dir\n",
    "\n",
    "# Daftar kelas (nama subfolder)\n",
    "classes = os.listdir(dataset_path)\n",
    "\n",
    "# Dictionary untuk menyimpan jumlah gambar dalam setiap kelas\n",
    "class_counts = {}\n",
    "\n",
    "# Iterasi melalui setiap kelas\n",
    "for class_name in classes:\n",
    "    class_folder = os.path.join(dataset_path, class_name)\n",
    "    if os.path.isdir(class_folder):\n",
    "        # Hitung jumlah file gambar dalam subfolder (kelas)\n",
    "        num_images = len([name for name in os.listdir(class_folder) if os.path.isfile(os.path.join(class_folder, name))])\n",
    "        class_counts[class_name] = num_images\n",
    "\n",
    "# Tampilkan jumlah gambar dalam setiap kelas\n",
    "for class_name, count in class_counts.items():\n",
    "    print(f\"Kelas {class_name}: {count} gambar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percobaan ke-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ditambahakan convert grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# import os\n",
    "\n",
    "# def adjust_bounding_box(bbox, original_size, new_size, flip_h=False, flip_v=False):\n",
    "#     xmin, ymin, xmax, ymax = bbox\n",
    "#     orig_w, orig_h = original_size\n",
    "#     new_w, new_h = new_size\n",
    "\n",
    "#     scale_x = new_w / orig_w\n",
    "#     scale_y = new_h / orig_h\n",
    "\n",
    "#     xmin_new = xmin * scale_x\n",
    "#     ymin_new = ymin * scale_y\n",
    "#     xmax_new = xmax * scale_x\n",
    "#     ymax_new = ymax * scale_y\n",
    "\n",
    "#     if flip_h:\n",
    "#         xmin_new, xmax_new = new_w - xmax_new, new_w - xmin_new\n",
    "\n",
    "#     if flip_v:\n",
    "#         ymin_new, ymax_new = new_h - ymax_new, new_h - ymin_new\n",
    "\n",
    "#     return xmin_new, ymin_new, xmax_new, ymax_new\n",
    "\n",
    "# def make_directory(path):\n",
    "#     if not os.path.exists(path):\n",
    "#         os.makedirs(path)\n",
    "\n",
    "# # Baca data dari CSV lama\n",
    "# df = pd.read_csv(\"../data/data_original/Pengenalan Aksara Jawa-tensorflow/train/_annotations.csv\")\n",
    "\n",
    "# # Daftar untuk menyimpan data yang telah diubah\n",
    "# new_data = []\n",
    "\n",
    "# # Direktori untuk menyimpan gambar dan label hasil augmentasi\n",
    "# original_dir = \"../data/data_original/Pengenalan Aksara Jawa-tensorflow/train/\"\n",
    "# augmented_path = \"../data/data_preprocessing/v1.2/\"\n",
    "# augmented_label_path = \"../data/data_preprocessing/v1.2/augmented_labels.csv\"\n",
    "# make_directory(augmented_path)\n",
    "\n",
    "# # ImageDataGenerator untuk augmentasi\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=19,\n",
    "#     width_shift_range=None,\n",
    "#     height_shift_range=None,\n",
    "#     shear_range=0.1,\n",
    "#     zoom_range=0.1,\n",
    "#     horizontal_flip=False,\n",
    "#     vertical_flip=False,\n",
    "#     fill_mode='nearest'\n",
    "# )\n",
    "\n",
    "# # Tentukan ukuran baru (misalnya, 96x96)\n",
    "# new_width, new_height = 96, 96\n",
    "\n",
    "# # Augmentasi setiap kelas sebanyak 100 kali\n",
    "# for class_name in df['class'].unique():\n",
    "#     class_df = df[df['class'] == class_name]\n",
    "    \n",
    "#     # Buat subfolder untuk kelas ini\n",
    "#     class_dir = os.path.join(augmented_path, class_name)\n",
    "#     make_directory(class_dir)\n",
    "    \n",
    "#     for i in range(30):\n",
    "#         for index, row in class_df.iterrows():\n",
    "#             filename = row['filename']\n",
    "#             orig_width = row['width']\n",
    "#             orig_height = row['height']\n",
    "#             class_name = row['class']\n",
    "#             xmin = row['xmin']\n",
    "#             ymin = row['ymin']\n",
    "#             xmax = row['xmax']\n",
    "#             ymax = row['ymax']\n",
    "\n",
    "#             image_path = os.path.join(original_dir, filename)\n",
    "#             image = cv2.imread(image_path)\n",
    "#             original_size = (orig_width, orig_height)\n",
    "\n",
    "#             # Convert image to grayscale\n",
    "#             gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#             # Convert image to array and expand dimensions\n",
    "#             image_array = np.expand_dims(gray_image, 0)\n",
    "\n",
    "#             # Augmentasi gambar\n",
    "#             for batch in datagen.flow(image_array, batch_size=1):\n",
    "#                 aug_image = batch[0].astype('uint8')\n",
    "\n",
    "#                 # Resize image\n",
    "#                 aug_image_resized = cv2.resize(aug_image, (new_width, new_height))\n",
    "\n",
    "#                 # Adjust bounding box\n",
    "#                 flip_h = 'horizontal_flip' in datagen.__dict__ and datagen.horizontal_flip\n",
    "#                 flip_v = 'vertical_flip' in datagen.__dict__ and datagen.vertical_flip\n",
    "#                 new_bbox = adjust_bounding_box((xmin, ymin, xmax, ymax), original_size, (new_width, new_height), flip_h, flip_v)\n",
    "\n",
    "#                 # Simpan gambar yang telah diubah\n",
    "#                 aug_filename = f'{filename.split(\".\")[0]}_aug_{i}_{index}.png'\n",
    "#                 aug_image_path = os.path.join(class_dir, aug_filename)\n",
    "#                 cv2.imwrite(aug_image_path, aug_image_resized)\n",
    "\n",
    "#                 # Tambahkan data baru ke daftar\n",
    "#                 new_data.append([aug_filename, new_width, new_height, class_name, *new_bbox])\n",
    "\n",
    "#                 break  # hanya menghasilkan satu augmentasi per gambar per iterasi\n",
    "\n",
    "# # Membuat DataFrame baru dari data yang telah diubah\n",
    "# new_df = pd.DataFrame(new_data, columns=['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
    "\n",
    "# # Menyimpan DataFrame ke CSV baru\n",
    "# new_df.to_csv(augmented_label_path, index=False)\n",
    "\n",
    "# print(\"Data bounding box yang telah diubah telah disimpan ke CSV baru dan gambar disimpan ke subfolder berdasarkan kelas.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
