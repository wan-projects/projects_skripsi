{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels CSV file created at: ../data/data_original/Pengenalan Aksara Jawa-tensorflow/clustering/labels.csv\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# def create_labels_csv(dataset_path, output_csv):\n",
    "#     # List to store image file paths and their corresponding labels\n",
    "#     data = []\n",
    "\n",
    "#     # Traverse the dataset directory\n",
    "#     for root, dirs, files in os.walk(dataset_path):\n",
    "#         for file in files:\n",
    "#             if file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "#                 # Get the class label from the subdirectory name\n",
    "#                 label = os.path.basename(root)\n",
    "#                 # Get the full file path\n",
    "#                 file_path = os.path.join(root, file)\n",
    "#                 # Append to the data list\n",
    "#                 data.append([file_path, label])\n",
    "    \n",
    "#     # Create a DataFrame from the data list\n",
    "#     df = pd.DataFrame(data, columns=['file_path', 'label'])\n",
    "    \n",
    "#     # Save the DataFrame to a CSV file\n",
    "#     df.to_csv(output_csv, index=False)\n",
    "#     print(f'Labels CSV file created at: {output_csv}')\n",
    "\n",
    "# # Usage\n",
    "# dataset_path = \"../data/data_original/Pengenalan Aksara Jawa-tensorflow/clustering/\"\n",
    "# output_csv = \"../data/data_original/Pengenalan Aksara Jawa-tensorflow/clustering/labels.csv\"\n",
    "# create_labels_csv(dataset_path, output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented images and labels CSV file created at: ../data/data_preprocessing/v2.2/augmented_labels.csv\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img, save_img\n",
    "\n",
    "# def augment_images(dataset_path, output_path, output_csv, augment_count=5):\n",
    "#     # Create an ImageDataGenerator object with augmentation parameters\n",
    "#     datagen = ImageDataGenerator(\n",
    "#         rotation_range=20,\n",
    "#         width_shift_range=None,\n",
    "#         height_shift_range=None,\n",
    "#         shear_range=0.0,\n",
    "#         zoom_range=0.0,\n",
    "#         horizontal_flip=False,\n",
    "#         vertical_flip=False,\n",
    "#         fill_mode='nearest'\n",
    "#     )\n",
    "    \n",
    "#     labels = []\n",
    "\n",
    "#     for class_dir in os.listdir(dataset_path):\n",
    "#         class_path = os.path.join(dataset_path, class_dir)\n",
    "#         if not os.path.isdir(class_path):\n",
    "#             continue\n",
    "        \n",
    "#         class_labels = []  # Keep track of labels for each class\n",
    "        \n",
    "#         for img_file in os.listdir(class_path):\n",
    "#             img_path = os.path.join(class_path, img_file)\n",
    "#             if not img_file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "#                 continue\n",
    "            \n",
    "#             img = load_img(img_path)\n",
    "#             x = img_to_array(img)\n",
    "#             x = x.reshape((1,) + x.shape)\n",
    "            \n",
    "#             i = 0\n",
    "#             for batch in datagen.flow(x, batch_size=1):\n",
    "#                 augmented_img = array_to_img(batch[0])\n",
    "#                 augmented_img_name = f'{os.path.splitext(img_file)[0]}_aug_{i}.png'\n",
    "#                 augmented_img_path = os.path.join(output_path, class_dir)\n",
    "#                 if not os.path.exists(augmented_img_path):\n",
    "#                     os.makedirs(augmented_img_path)\n",
    "                \n",
    "#                 save_img(os.path.join(augmented_img_path, augmented_img_name), augmented_img)\n",
    "#                 class_labels.append([os.path.join(augmented_img_path, augmented_img_name), class_dir])\n",
    "#                 i += 1\n",
    "#                 if i >= augment_count:\n",
    "#                     break\n",
    "#             break\n",
    "        \n",
    "#         labels.extend(class_labels)  # Append the labels for this class to the main list\n",
    "    \n",
    "#     # Save labels to CSV\n",
    "#     df = pd.DataFrame(labels, columns=['file_path', 'label'])\n",
    "#     df.to_csv(output_csv, index=False)\n",
    "#     print(f'Augmented images and labels CSV file created at: {output_csv}')\n",
    "\n",
    "# # Usage\n",
    "# dataset_path = \"../data/data_original/Pengenalan Aksara Jawa-tensorflow/clustering/\"\n",
    "# output_path = \"../data/data_preprocessing/v2.2/\"\n",
    "# output_csv = '../data/data_preprocessing/v2.2/augmented_labels.csv'\n",
    "# augment_images(dataset_path, output_path, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented images and labels CSV file created at: ../data/data_preprocessing/v2.2/augmented_labels.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img, save_img\n",
    "\n",
    "def augment_images(dataset_path, output_path, output_csv, augment_count=650):\n",
    "    # Create an ImageDataGenerator object with augmentation parameters\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    labels = []\n",
    "\n",
    "    for class_dir in os.listdir(dataset_path):\n",
    "        class_path = os.path.join(dataset_path, class_dir)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        \n",
    "        class_labels = []  # Keep track of labels for each class\n",
    "        \n",
    "        img_files = [f for f in os.listdir(class_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        num_images = len(img_files)\n",
    "        \n",
    "        if num_images == 0:\n",
    "            continue\n",
    "        \n",
    "        augmentations_per_image = augment_count // num_images\n",
    "        \n",
    "        for img_file in img_files:\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            \n",
    "            img = load_img(img_path)\n",
    "            x = img_to_array(img)\n",
    "            x = x.reshape((1,) + x.shape)\n",
    "            \n",
    "            i = 0\n",
    "            for batch in datagen.flow(x, batch_size=1):\n",
    "                augmented_img = array_to_img(batch[0])\n",
    "                augmented_img_name = f'{os.path.splitext(img_file)[0]}_aug_{i}.png'\n",
    "                augmented_img_path = os.path.join(output_path, class_dir)\n",
    "                if not os.path.exists(augmented_img_path):\n",
    "                    os.makedirs(augmented_img_path)\n",
    "                \n",
    "                save_img(os.path.join(augmented_img_path, augmented_img_name), augmented_img)\n",
    "                class_labels.append([os.path.join(augmented_img_path, augmented_img_name), class_dir])\n",
    "                i += 1\n",
    "                if i >= augmentations_per_image:\n",
    "                    break\n",
    "        \n",
    "        labels.extend(class_labels)  # Append the labels for this class to the main list\n",
    "    \n",
    "    # Save labels to CSV\n",
    "    df = pd.DataFrame(labels, columns=['file_path', 'label'])\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f'Augmented images and labels CSV file created at: {output_csv}')\n",
    "\n",
    "# Usage\n",
    "dataset_path = \"../data/data_original/Pengenalan Aksara Jawa-tensorflow/clustering/\"\n",
    "output_path = \"../data/data_preprocessing/v2./\"\n",
    "output_csv = '../data/data_preprocessing/v2./augmented_labels.csv'\n",
    "augment_images(dataset_path, output_path, output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelas class 1: 630 gambar\n",
      "Kelas class 2: 640 gambar\n",
      "Kelas class 3: 638 gambar\n",
      "Kelas class 4: 650 gambar\n",
      "Kelas class 5: 638 gambar\n",
      "Kelas class 6: 646 gambar\n",
      "Kelas class 7: 650 gambar\n"
     ]
    }
   ],
   "source": [
    "# Lokasi direktori dataset asli\n",
    "dataset_path = output_path\n",
    "\n",
    "# Daftar kelas (nama subfolder)\n",
    "classes = os.listdir(dataset_path)\n",
    "\n",
    "# Dictionary untuk menyimpan jumlah gambar dalam setiap kelas\n",
    "class_counts = {}\n",
    "\n",
    "# Iterasi melalui setiap kelas\n",
    "for class_name in classes:\n",
    "    class_folder = os.path.join(dataset_path, class_name)\n",
    "    if os.path.isdir(class_folder):\n",
    "        # Hitung jumlah file gambar dalam subfolder (kelas)\n",
    "        num_images = len([name for name in os.listdir(class_folder) if os.path.isfile(os.path.join(class_folder, name))])\n",
    "        class_counts[class_name] = num_images\n",
    "\n",
    "# Tampilkan jumlah gambar dalam setiap kelas\n",
    "for class_name, count in class_counts.items():\n",
    "    print(f\"Kelas {class_name}: {count} gambar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percobaan Yang lain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented images and labels CSV file created at: ../data/data_preprocessing/v2.5/augmented_labels.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img, save_img\n",
    "from PIL import Image\n",
    "\n",
    "def augment_images(dataset_path, output_path, output_csv, augment_count=650, target_size=(128, 128)):\n",
    "    # Create an ImageDataGenerator object with augmentation parameters\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0,\n",
    "        height_shift_range=0,\n",
    "        shear_range=0,\n",
    "        zoom_range=0,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    labels = []\n",
    "\n",
    "    for class_dir in os.listdir(dataset_path):\n",
    "        class_path = os.path.join(dataset_path, class_dir)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        \n",
    "        class_labels = []  # Keep track of labels for each class\n",
    "        \n",
    "        img_files = [f for f in os.listdir(class_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        num_images = len(img_files)\n",
    "        \n",
    "        if num_images == 0:\n",
    "            continue\n",
    "        \n",
    "        augmentations_per_image = augment_count // num_images\n",
    "        \n",
    "        for img_file in img_files:\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            \n",
    "            img = load_img(img_path)\n",
    "            x = img_to_array(img)\n",
    "            x = x.reshape((1,) + x.shape)\n",
    "            \n",
    "            i = 0\n",
    "            for batch in datagen.flow(x, batch_size=1):\n",
    "                augmented_img = array_to_img(batch[0])\n",
    "                \n",
    "                # Resize the augmented image\n",
    "                augmented_img = augmented_img.resize(target_size, Image.LANCZOS)\n",
    "                \n",
    "                augmented_img_name = f'{os.path.splitext(img_file)[0]}_aug_{i}.png'\n",
    "                augmented_img_path = os.path.join(output_path, class_dir)\n",
    "                if not os.path.exists(augmented_img_path):\n",
    "                    os.makedirs(augmented_img_path)\n",
    "                \n",
    "                save_img(os.path.join(augmented_img_path, augmented_img_name), augmented_img)\n",
    "                class_labels.append([os.path.join(augmented_img_path, augmented_img_name), class_dir])\n",
    "                i += 1\n",
    "                if i >= augmentations_per_image:\n",
    "                    break\n",
    "        \n",
    "        labels.extend(class_labels)  # Append the labels for this class to the main list\n",
    "    \n",
    "    # Save labels to CSV\n",
    "    df = pd.DataFrame(labels, columns=['file_path', 'label'])\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f'Augmented images and labels CSV file created at: {output_csv}')\n",
    "\n",
    "# Usage\n",
    "dataset_path = \"../data/data_original/Pengenalan Aksara Jawa-tensorflow/clustering/\"\n",
    "output_path = \"../data/data_preprocessing/v2.5/\"\n",
    "output_csv = '../data/data_preprocessing/v2.5/augmented_labels.csv'\n",
    "augment_images(dataset_path, output_path, output_csv, target_size=(128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelas class 1: 630 gambar\n",
      "Kelas class 2: 640 gambar\n",
      "Kelas class 3: 638 gambar\n",
      "Kelas class 4: 650 gambar\n",
      "Kelas class 5: 638 gambar\n",
      "Kelas class 6: 646 gambar\n",
      "Kelas class 7: 650 gambar\n"
     ]
    }
   ],
   "source": [
    "# Lokasi direktori dataset asli\n",
    "dataset_path = output_path\n",
    "\n",
    "# Daftar kelas (nama subfolder)\n",
    "classes = os.listdir(dataset_path)\n",
    "\n",
    "# Dictionary untuk menyimpan jumlah gambar dalam setiap kelas\n",
    "class_counts = {}\n",
    "\n",
    "# Iterasi melalui setiap kelas\n",
    "for class_name in classes:\n",
    "    class_folder = os.path.join(dataset_path, class_name)\n",
    "    if os.path.isdir(class_folder):\n",
    "        # Hitung jumlah file gambar dalam subfolder (kelas)\n",
    "        num_images = len([name for name in os.listdir(class_folder) if os.path.isfile(os.path.join(class_folder, name))])\n",
    "        class_counts[class_name] = num_images\n",
    "\n",
    "# Tampilkan jumlah gambar dalam setiap kelas\n",
    "for class_name, count in class_counts.items():\n",
    "    print(f\"Kelas {class_name}: {count} gambar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
