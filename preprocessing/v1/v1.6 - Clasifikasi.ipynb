{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melakukan Augmentasi Data pada tanggal 13 Juni 2024 jam 21.00 WIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented images and labels CSV file created at: ../data/data_preprocessing/v2.3/augmented_labels.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img, save_img\n",
    "from PIL import Image\n",
    "\n",
    "def augment_images(dataset_path, output_path, output_csv, augment_count=1000, target_size=(128, 128)):\n",
    "    # Create an ImageDataGenerator object with augmentation parameters\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0,\n",
    "        height_shift_range=0,\n",
    "        shear_range=0,\n",
    "        zoom_range=0,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    labels = []\n",
    "\n",
    "    for class_dir in os.listdir(dataset_path):\n",
    "        class_path = os.path.join(dataset_path, class_dir)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        \n",
    "        class_labels = []  # Keep track of labels for each class\n",
    "        \n",
    "        img_files = [f for f in os.listdir(class_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        num_images = len(img_files)\n",
    "        \n",
    "        if num_images == 0:\n",
    "            continue\n",
    "        \n",
    "        augmentations_per_image = augment_count // num_images\n",
    "        \n",
    "        for img_file in img_files:\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            \n",
    "            img = load_img(img_path)\n",
    "            x = img_to_array(img)\n",
    "            x = x.reshape((1,) + x.shape)\n",
    "            \n",
    "            i = 0\n",
    "            for batch in datagen.flow(x, batch_size=1):\n",
    "                augmented_img = array_to_img(batch[0])\n",
    "                \n",
    "                # Resize the augmented image\n",
    "                augmented_img = augmented_img.resize(target_size, Image.LANCZOS)\n",
    "                \n",
    "                augmented_img_name = f'{os.path.splitext(img_file)[0]}_aug_{i}.png'\n",
    "                augmented_img_path = os.path.join(output_path, class_dir)\n",
    "                if not os.path.exists(augmented_img_path):\n",
    "                    os.makedirs(augmented_img_path)\n",
    "                \n",
    "                save_img(os.path.join(augmented_img_path, augmented_img_name), augmented_img)\n",
    "                \n",
    "                class_labels.append([os.path.join(augmented_img_path, augmented_img_name), class_dir])\n",
    "                \n",
    "                i += 1\n",
    "                if i >= augmentations_per_image:\n",
    "                    break\n",
    "        \n",
    "        labels.extend(class_labels)  # Append the labels for this class to the main list\n",
    "    \n",
    "    # Save labels to CSV\n",
    "    df = pd.DataFrame(labels, columns=['file_path', 'label'])\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f'Augmented images and labels CSV file created at: {output_csv}')\n",
    "\n",
    "# Usage\n",
    "dataset_path = \"../data/data_original/Pengenalan Aksara Jawa-tensorflow/CustomData/v0.1 - Clasifikasi Class\"\n",
    "output_path = \"../data/data_preprocessing/v2.3/\"\n",
    "output_csv = '../data/data_preprocessing/v2.3/augmented_labels.csv'\n",
    "\n",
    "augment_images(dataset_path, output_path, output_csv, target_size=(128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelas class 1: 990 gambar\n",
      "Kelas class 2: 992 gambar\n",
      "Kelas class 3: 990 gambar\n",
      "Kelas class 4: 988 gambar\n",
      "Kelas class 5: 990 gambar\n",
      "Kelas class 6: 986 gambar\n",
      "Kelas class 7: 988 gambar\n"
     ]
    }
   ],
   "source": [
    "# Lokasi direktori dataset asli\n",
    "dataset_path = output_path\n",
    "\n",
    "# Daftar kelas (nama subfolder)\n",
    "classes = os.listdir(dataset_path)\n",
    "\n",
    "# Dictionary untuk menyimpan jumlah gambar dalam setiap kelas\n",
    "class_counts = {}\n",
    "\n",
    "# Iterasi melalui setiap kelas\n",
    "for class_name in classes:\n",
    "    class_folder = os.path.join(dataset_path, class_name)\n",
    "    if os.path.isdir(class_folder):\n",
    "        # Hitung jumlah file gambar dalam subfolder (kelas)\n",
    "        num_images = len([name for name in os.listdir(class_folder) if os.path.isfile(os.path.join(class_folder, name))])\n",
    "        class_counts[class_name] = num_images\n",
    "\n",
    "# Tampilkan jumlah gambar dalam setiap kelas\n",
    "for class_name, count in class_counts.items():\n",
    "    print(f\"Kelas {class_name}: {count} gambar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengatasi Imbalanced Dataset atau ketidak seimbangan data menggunakan Metode Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Path dataset\n",
    "# data = output_img_aug\n",
    "\n",
    "# # List kelas\n",
    "# kelas_aksara = ['ba', 'ca', 'da', 'dha', 'ga', 'ha', 'ja', 'ka', 'la', 'ma', 'na', 'nga', 'nya', 'pa', 'ra', 'sa', 'ta', 'tha', 'wa', 'ya']\n",
    "\n",
    "# # Target jumlah gambar per kelas\n",
    "# target_jumlah = 493\n",
    "\n",
    "# # Loop untuk setiap kelas\n",
    "# for kelas in kelas_aksara:\n",
    "#     # Path kelas\n",
    "#     kelas_path = os.path.join(data, kelas)\n",
    "    \n",
    "#     # Jumlah gambar saat ini\n",
    "#     jumlah_gambar = len(os.listdir(kelas_path))\n",
    "    \n",
    "#     # Selisih gambar yang perlu ditambahkan\n",
    "#     selisih = target_jumlah - jumlah_gambar\n",
    "    \n",
    "#     # Jika selisih positif, lakukan oversampling\n",
    "#     if selisih > 0:\n",
    "#         # Ambil sampel acak dari gambar yang sudah ada\n",
    "#         gambar_oversampling = random.sample(os.listdir(kelas_path), selisih)\n",
    "        \n",
    "#         # Copy gambar oversampling ke dalam kelas\n",
    "#         for gambar in gambar_oversampling:\n",
    "#             source_path = os.path.join(kelas_path, gambar)\n",
    "            \n",
    "#             # Generate sufiks acak\n",
    "#             sufiks_acak = ''.join(random.choices(string.ascii_letters + string.digits, k=8))\n",
    "            \n",
    "#             # Tentukan path tujuan dengan menambahkan sufiks acak\n",
    "#             target_path = os.path.join(kelas_path, f'{os.path.splitext(gambar)[0]}_{sufiks_acak}{os.path.splitext(gambar)[1]}')\n",
    "            \n",
    "#             # Salin gambar ke target path\n",
    "#             shutil.copy(source_path, target_path)\n",
    "\n",
    "# # Cetak ulang jumlah gambar per kelas setelah penyamaan\n",
    "# for kelas in kelas_aksara:\n",
    "#     kelas_path = os.path.join(data, kelas)\n",
    "#     jumlah_gambar = len(os.listdir(kelas_path))\n",
    "#     print(f'Aksara {kelas} jumlah: {jumlah_gambar}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
