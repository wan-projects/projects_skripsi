{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cec7681c-bd90-41a6-bd04-83069fd126d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Install and import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f231f8a8-1f87-40d8-a631-198e46f33982",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\wawn1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential\n",
    "from keras.applications import VGG16\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13d13db-252a-49ea-af8d-dbdca1ca1acf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26e7975-14ee-455f-baf7-828cb752532c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generator data gambar dengan rescaling\n",
    "image_generator = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    ")\n",
    " \n",
    "# Tentukan ukuran gambar\n",
    "size_w = 150\n",
    "size_h = size_w\n",
    "size = (size_w, size_h)\n",
    "\n",
    "batch = 32\n",
    " \n",
    "# Tentukan jalur direktori untuk data latih, validasi, dan uji\n",
    "train_dir = '../TA/original_dataset/train'\n",
    "val_dir = '../TA/original_dataset/val'\n",
    "test_dir = '../TA/original_dataset/test'\n",
    "\n",
    "# Alirkan data dari direktori untuk data latih\n",
    "train_data = image_generator.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=size,\n",
    "    batch_size=batch,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb'\n",
    ")\n",
    "\n",
    "# Alirkan data dari direktori untuk data validasi\n",
    "validation_data = image_generator.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=size,\n",
    "    batch_size=batch,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb'\n",
    ")\n",
    "\n",
    "# Alirkan data dari direktori untuk data uji\n",
    "test_data = image_generator.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=size,\n",
    "    batch_size=batch,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de890483-5a4c-4b5a-9599-74065435f9ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def switch_dict_key_values(this_dict):\n",
    "    return dict((v,k) for k,v in this_dict.items())\n",
    "\n",
    "classes_name = switch_dict_key_values(train_data.class_indices)\n",
    "print(classes_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e2d2c8-6f19-49ee-8f94-70d9e6b2fa37",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a8bff1-8452-447d-925c-bb337fee6421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained VGG16 model\n",
    "base_model = VGG16(weights=None, include_top=False, input_shape=(size_w, size_h, 3))\n",
    " \n",
    "# Create a new model on top of the pre-trained VGG16\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "\n",
    "# Add Batch Normalization for data normalization\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "# Add additional convolutional layers with weight decay\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2, 2, padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2, 2, padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2, 2, padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Flatten and add fully connected layers with Dropout\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(20, activation='softmax'))\n",
    "\n",
    "# Menampilkan ringkasan model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34369f2a-163f-4fa5-ba57-9869aae7a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kompilasi model dengan optimizer Adam, menggunakan gradient clipping\n",
    "opt = Adam(learning_rate=0.0001, clipnorm=1.0)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Definisi callback EarlyStopping untuk mencegah overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0613a1ae-abfb-44cd-a9e6-f2d90029ef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "epochs = 5\n",
    "history = model.fit(\n",
    "    train_data, \n",
    "    epochs=epochs,\n",
    "    batch_size = 64,\n",
    "    validation_data=validation_data, \n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d6535b-b073-453d-99ad-5eef91b83173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_data)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
