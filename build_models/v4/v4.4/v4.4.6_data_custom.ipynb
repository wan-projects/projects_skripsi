{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c03f9bba",
   "metadata": {},
   "source": [
    "# Note\n",
    "1. Melakukan percobaan build_models v4.0\n",
    "2. Dilakukan pada hari Senin, 29 Juli 2024\n",
    "3. Tempat di Kost\n",
    "4. Data menggunakan Dataset yang dari Roboflow \n",
    "4. Meliputi Class: 20 Kelas Aksara Jawa:\n",
    "- Ba, Ca, Da, Dha, Ga, Ha, Ja, Ka, La, Ma, \n",
    "- Na, Nga, Nya, Pa, Ra, Sa, Ta, Tha, Wa, Ya"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7072e1a6",
   "metadata": {},
   "source": [
    "# Setup Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deba1394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ec1c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef06ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4253cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b90208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5278c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea06228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79de6efd",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e8d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt  \n",
    "# import os\n",
    "# from os.path import join\n",
    "# import random\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "# from keras.models import Sequential\n",
    "# from tensorflow.keras import layers, models\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "# from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization , Activation,Conv2D\n",
    "# from keras.optimizers import Adam\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "# from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "# from sklearn.metrics import classification_report\n",
    "# import seaborn as sns\n",
    "# from sklearn.metrics import classification_report, accuracy_score,roc_curve,confusion_matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f8462d",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "172c2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import cv2\n",
    "\n",
    "# def convert_to_png(image_path, output_path):\n",
    "#     # Read the image using OpenCV\n",
    "#     image = cv2.imread(image_path)\n",
    "#     # Create the output directory if it doesn't exist\n",
    "#     os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "#     # Save the image as PNG\n",
    "#     cv2.imwrite(output_path, image)\n",
    "\n",
    "# def get_last_n_parts(path, n):\n",
    "#     return os.path.join(*path.split(os.sep)[-n:])\n",
    "\n",
    "# def create_labels_csv(DATASET_PATH, OUTPUT_CSV, OUTPUT_IMAGE_DIR):\n",
    "#     # List to store image file paths and their corresponding labels and dimensions\n",
    "#     data = []\n",
    "\n",
    "#     # Traverse the dataset directory\n",
    "#     for root, dirs, files in os.walk(DATASET_PATH):\n",
    "#         for file in files:\n",
    "#             if file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "#                 # Get the class label from the subdirectory name\n",
    "#                 label = os.path.basename(root)\n",
    "#                 # Get the full file path\n",
    "#                 file_path = os.path.join(root, file)\n",
    "                \n",
    "#                 # Create a new file path for the PNG image\n",
    "#                 relative_path = os.path.relpath(file_path, DATASET_PATH)\n",
    "#                 png_file_path = os.path.join(OUTPUT_IMAGE_DIR, os.path.splitext(relative_path)[0] + '.png')\n",
    "                \n",
    "#                 # Convert the image to PNG\n",
    "#                 convert_to_png(file_path, png_file_path)\n",
    "                \n",
    "#                 # Get image dimensions\n",
    "#                 img = cv2.imread(file_path)\n",
    "#                 height, width, _ = img.shape\n",
    "                \n",
    "#                 # Get only the last 3 parts of the path for CSV\n",
    "#                 csv_path = get_last_n_parts(png_file_path, 2)\n",
    "                \n",
    "#                 # Append to the data list including dimensions\n",
    "#                 data.append([csv_path, width, height, label])\n",
    "    \n",
    "#     # Create a DataFrame from the data list\n",
    "#     df = pd.DataFrame(data, columns=['file_path', 'width', 'height', 'label'])\n",
    "    \n",
    "#     # Save the DataFrame to a CSV file\n",
    "#     df.to_csv(OUTPUT_CSV, index=False)\n",
    "#     print(f'Labels CSV file created at: {OUTPUT_CSV}')\n",
    "\n",
    "# # Define the paths for the two datasets and their respective output directories\n",
    "# DATASET_PATH = \"C:\\\\Users\\\\wawn1\\\\projects_skripsi\\\\data\\\\data_original\\\\Dataset_Collection_4_Data_Sources\\\\\"\n",
    "# OUTPUT_CSV = \"C:\\\\Users\\\\wawn1\\\\projects_skripsi\\\\data\\\\data_preprocessing\\\\v3.6_data_collection\\\\labels.csv\"\n",
    "# OUTPUT_IMAGE_DIR = \"C:\\\\Users\\\\wawn1\\\\projects_skripsi\\\\data\\\\data_preprocessing\\\\v3.6_data_collection\\\\\"\n",
    "\n",
    "# # Process the first dataset\n",
    "# create_labels_csv(DATASET_PATH, OUTPUT_CSV, OUTPUT_IMAGE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aad9c781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ba\\002798ad-631c-4f0c-b899-aa66fb5c2ac1.png</td>\n",
       "      <td>239</td>\n",
       "      <td>167</td>\n",
       "      <td>ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ba\\040ab1c7-bffa-4a93-8c42-54e5597f2243.png</td>\n",
       "      <td>96</td>\n",
       "      <td>67</td>\n",
       "      <td>ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba\\0789a0d8-e129-48ec-b74e-2e53f4a7ece9.png</td>\n",
       "      <td>235</td>\n",
       "      <td>166</td>\n",
       "      <td>ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ba\\11f6c317-635a-4e64-8552-05bf8b7b3a95.png</td>\n",
       "      <td>96</td>\n",
       "      <td>67</td>\n",
       "      <td>ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ba\\13469389-6f9b-43dc-be99-8dfbfaae51cb.png</td>\n",
       "      <td>235</td>\n",
       "      <td>165</td>\n",
       "      <td>ba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     file_path  width  height label\n",
       "0  ba\\002798ad-631c-4f0c-b899-aa66fb5c2ac1.png    239     167    ba\n",
       "1  ba\\040ab1c7-bffa-4a93-8c42-54e5597f2243.png     96      67    ba\n",
       "2  ba\\0789a0d8-e129-48ec-b74e-2e53f4a7ece9.png    235     166    ba\n",
       "3  ba\\11f6c317-635a-4e64-8552-05bf8b7b3a95.png     96      67    ba\n",
       "4  ba\\13469389-6f9b-43dc-be99-8dfbfaae51cb.png    235     165    ba"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path ke dua file CSV yang berbeda\n",
    "path_main = \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\data\\\\data_preprocessing\\\\v3.6_data_collection\\\\\"\n",
    "file = path_main + \"labels.csv\"\n",
    "df = pd.read_csv(file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13f1ce57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Define function to count files in each directory\n",
    "def count_files(link):\n",
    "    path = link\n",
    "    num_files = len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))])\n",
    "    return num_files\n",
    "\n",
    "# Define paths for two sources\n",
    "source_paths = [\n",
    "    \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\data\\\\data_preprocessing\\\\v3.6_data_collection\\\\ba\",\n",
    "    \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\data\\\\data_preprocessing\\\\v3.6_data_collection\\\\ca\",\n",
    "    \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\data\\\\data_preprocessing\\\\v3.6_data_collection\\\\da\",\n",
    "    \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\data\\\\data_preprocessing\\\\v3.6_data_collection\\\\dha\",\n",
    "    \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\data\\\\data_preprocessing\\\\v3.6_data_collection\\\\ga\",\n",
    "    \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\data\\\\data_preprocessing\\\\v3.6_data_collection\\\\ha\",\n",
    "    \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\data\\\\data_preprocessing\\\\v3.6_data_collection\\\\ja\",\n",
    "    \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\data\\\\data_preprocessing\\\\v3.6_data_collection\\\\ka\",\n",
    "    \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\data\\\\data_preprocessing\\\\v3.6_data_collection\\\\la\",\n",
    "    \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\data\\\\data_preprocessing\\\\v3.6_data_collection\\\\ma\",\n",
    "    \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\data\\\\data_preprocessing\\\\v3.6_data_collection\\\\na\",\n",
    "    \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\data\\\\data_preprocessing\\\\v3.6_data_collection\\\\nga\",\n",
    "    \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\data\\\\data_preprocessing\\\\v3.6_data_collection\\\\nya\",\n",
    "    \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\data\\\\data_preprocessing\\\\v3.6_data_collection\\\\pa\",\n",
    "    \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\data\\\\data_preprocessing\\\\v3.6_data_collection\\\\ra\",\n",
    "    \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\data\\\\data_preprocessing\\\\v3.6_data_collection\\\\sa\",\n",
    "    \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\data\\\\data_preprocessing\\\\v3.6_data_collection\\\\ta\",\n",
    "    \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\data\\\\data_preprocessing\\\\v3.6_data_collection\\\\tha\",\n",
    "    \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\data\\\\data_preprocessing\\\\v3.6_data_collection\\\\wa\",\n",
    "    \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\data\\\\data_preprocessing\\\\v3.6_data_collection\\\\ya\"\n",
    "]\n",
    "\n",
    "# Count files for each path\n",
    "file_counts = [count_files(path) for path in source_paths]\n",
    "\n",
    "# Define the input path aksara\n",
    "aksara_categories = ['ba', 'ca', 'da', 'dha', 'ga', 'ha', 'ja', 'ka', 'la', 'Ma', 'na',\n",
    "                     'nga', 'nya', 'pa', 'ra', 'sa', 'ta', 'tha', 'wa', 'ya']\n",
    "\n",
    "colors = ['red', 'orange', 'yellow', 'green', 'blue', 'pink', 'indigo', 'purple', \n",
    "          'cyan', 'magenta', 'lime', 'maroon', 'navy', 'olive', 'orchid', 'peru', \n",
    "          'salmon', 'sienna', 'skyblue', 'tan']  # Colors for each bar\n",
    "\n",
    "# Create bar chart\n",
    "plt.figure(figsize=(9, 4))\n",
    "plt.bar(aksara_categories, file_counts, color=colors)\n",
    "plt.xlabel('Kategori Aksara', fontsize=14)\n",
    "plt.ylabel('Jumlah Gambar', fontsize=14)\n",
    "plt.title('Jumlah Gambar Aksara Jawa', fontsize=16)\n",
    "plt.xticks(fontsize=10, rotation=10)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b257451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the input path and aksaraJowo\n",
    "INPUT_PATH = path_main  \n",
    "AKSARA = aksara_categories\n",
    "\n",
    "# Define the target image size\n",
    "IMAGE_SIZE = (96, 96)\n",
    "INPUT_SHAPE = (96, 96, 1)\n",
    "\n",
    "def create_image_generator(input_path, aksaraJowo, image_size):\n",
    "    for index, jowo in enumerate(aksaraJowo):\n",
    "        aksara_path = os.path.join(input_path, jowo)\n",
    "        \n",
    "        for filename in os.listdir(aksara_path):\n",
    "            image_path = os.path.join(aksara_path, filename)\n",
    "            original_image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)  # Baca dan ubah warna asli\n",
    "            original_image_resized = cv2.resize(original_image, image_size, interpolation=cv2.INTER_AREA)  # Resize gambar asli\n",
    "            grayscale_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Baca gambar sebagai grayscale\n",
    "            grayscale_image_resized = cv2.resize(grayscale_image, image_size, interpolation=cv2.INTER_AREA)  # Resize gambar grayscale\n",
    "            image_filtered = apply_custom_preprocessing(grayscale_image_resized)\n",
    "            \n",
    "            yield original_image_resized, grayscale_image_resized, image_filtered, index\n",
    "\n",
    "\n",
    "def load_images(input_path, aksaraJowo, image_size):\n",
    "    X_original, X_grayscale, X_filtered, y_label = [], [], [], []\n",
    "    \n",
    "    for original_image, grayscale_image, image_filtered, label in create_image_generator(input_path, aksaraJowo, image_size):\n",
    "        X_original.append(original_image)\n",
    "        X_grayscale.append(grayscale_image)\n",
    "        X_filtered.append(image_filtered)\n",
    "        y_label.append(label)\n",
    "        \n",
    "    X_original = np.array(X_original)\n",
    "    X_grayscale = np.array(X_grayscale)\n",
    "    X_filtered = np.array(X_filtered)\n",
    "    y_label = to_categorical(np.array(y_label))\n",
    "    \n",
    "    return X_original, X_grayscale, X_filtered, y_label\n",
    "\n",
    "def apply_custom_preprocessing(image):\n",
    "    # Apply Gaussian Blur\n",
    "    ApplyGaussian = cv2.GaussianBlur(image, (15, 15), 0.1)\n",
    "    # Enhance the image sharpness\n",
    "    img = cv2.addWeighted(image, 1.5, ApplyGaussian, -0.5, 0, image)\n",
    "    # Apply sharpening filter\n",
    "    kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
    "    img = cv2.filter2D(img, -1, kernel)\n",
    "    # Remove noise using median filter\n",
    "    img = cv2.medianBlur(img, 1)\n",
    "    # Apply Otsu's thresholding\n",
    "    _, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    img = 255 - img\n",
    "    \n",
    "    # Apply dilation to thicken the lines\n",
    "    kernel = np.ones((2, 2), np.uint8)  # You can adjust the kernel size\n",
    "    img = cv2.dilate(img, kernel, iterations=1)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Load images with custom preprocessing applied\n",
    "X_original, X_grayscale, X_filtered, y_label = load_images(INPUT_PATH, AKSARA, IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bcd0ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select one image to display\n",
    "index_to_display = 14\n",
    "\n",
    "# Display the original image, grayscale image, and filtered image\n",
    "original_image = X_original[index_to_display]\n",
    "grayscale_image = X_grayscale[index_to_display]\n",
    "filtered_image = X_filtered[index_to_display]\n",
    "\n",
    "# Plot the images\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(original_image)\n",
    "plt.axis('on')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Grayscale Image')\n",
    "plt.imshow(grayscale_image)\n",
    "plt.axis('on')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Filtered Image')\n",
    "# plt.imshow(filtered_image, cmap='gray')\n",
    "plt.imshow(filtered_image, cmap='gray')\n",
    "plt.axis('on')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1be84d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_filtered shape after reshape: (4355, 96, 96, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshape X_filtered\n",
    "X_filtered_reshaped = X_filtered.reshape(-1, 96, 96, 1).astype(\"float32\") / 255  # Reshape dan normalisasi\n",
    "# X_filtered_reshaped = X_filtered.reshape(-1, 96, 96, 1) / 255  # Reshape dan normalisasi\n",
    "\n",
    "print(\"X_filtered shape after reshape:\", X_filtered_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d223feaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran data pelatihan: (3484, 96, 96, 1) (3484, 20)\n",
      "Ukuran data pengujian: (871, 96, 96, 1) (871, 20)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Tahap pertama: Membagi data menjadi data pelatihan (80%) dan data pengujian (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_filtered_reshaped, y_label, test_size=0.2, random_state=54)\n",
    "\n",
    "# # Tahap kedua: Membagi data sementara menjadi data validasi (20%) dan data pengujian (10%)\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=1/3, random_state=37)\n",
    "\n",
    "# Verifikasi ukuran data\n",
    "print(\"Ukuran data pelatihan:\", X_train.shape, y_train.shape)\n",
    "# print(\"Ukuran data validasi:\", X_val.shape, y_val.shape)\n",
    "print(\"Ukuran data pengujian:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8ab1c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Menampilkan salah satu gambar dari data pelatihan\n",
    "plt.imshow(X_train[11], cmap='gray')\n",
    "plt.title(\"Sample Image in Class {} from Training Data !!!\".format(AKSARA[np.argmax(y_train[11])]))\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1bd922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Menampilkan salah satu gambar dari data validasi\n",
    "# plt.imshow(X_val[0], cmap='gray')\n",
    "# plt.title(\"Sample Image in Class {} from Validasi Data !!!\".format(AKSARA[np.argmax(y_val[0])]))\n",
    "# plt.axis('on')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65f3b0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Menampilkan salah satu gambar dari data pelatihan\n",
    "plt.imshow(X_test[15], cmap='gray')\n",
    "plt.title(\"Sample Image in Class {} from Testing Data !!!\".format(AKSARA[np.argmax(y_test[15])]))\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c1a8ed",
   "metadata": {},
   "source": [
    "# Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e967ad7",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c3df384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> \n",
       "\n",
       " batch_normalization_15           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> \n",
       "\n",
       " batch_normalization_16           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> \n",
       "\n",
       " batch_normalization_17           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> \n",
       "\n",
       " batch_normalization_18           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> \n",
       "\n",
       " batch_normalization_19           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> \n",
       "\n",
       " batch_normalization_20           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> \n",
       "\n",
       " batch_normalization_21           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> \n",
       "\n",
       " batch_normalization_22           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> \n",
       "\n",
       " batch_normalization_23           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> \n",
       "\n",
       " batch_normalization_24           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> \n",
       "\n",
       " batch_normalization_25           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> \n",
       "\n",
       " batch_normalization_26           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> \n",
       "\n",
       " batch_normalization_27           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,616</span> \n",
       "\n",
       " batch_normalization_28           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> \n",
       "\n",
       " batch_normalization_29           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,260</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m32\u001b[0m)                \u001b[38;5;34m320\u001b[0m \n",
       "\n",
       " batch_normalization_15           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m32\u001b[0m)                \u001b[38;5;34m128\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m32\u001b[0m)              \u001b[38;5;34m9,248\u001b[0m \n",
       "\n",
       " batch_normalization_16           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m32\u001b[0m)                \u001b[38;5;34m128\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout_7 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)             \u001b[38;5;34m18,496\u001b[0m \n",
       "\n",
       " batch_normalization_17           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)                \u001b[38;5;34m256\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)             \u001b[38;5;34m36,928\u001b[0m \n",
       "\n",
       " batch_normalization_18           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)                \u001b[38;5;34m256\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout_8 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m73,856\u001b[0m \n",
       "\n",
       " batch_normalization_19           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)               \u001b[38;5;34m512\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)           \u001b[38;5;34m147,584\u001b[0m \n",
       "\n",
       " batch_normalization_20           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)               \u001b[38;5;34m512\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)           \u001b[38;5;34m147,584\u001b[0m \n",
       "\n",
       " batch_normalization_21           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)               \u001b[38;5;34m512\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout_9 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)           \u001b[38;5;34m295,168\u001b[0m \n",
       "\n",
       " batch_normalization_22           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)             \u001b[38;5;34m1,024\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)           \u001b[38;5;34m590,080\u001b[0m \n",
       "\n",
       " batch_normalization_23           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)             \u001b[38;5;34m1,024\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)           \u001b[38;5;34m590,080\u001b[0m \n",
       "\n",
       " batch_normalization_24           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)             \u001b[38;5;34m1,024\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout_10 (\u001b[38;5;33mDropout\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)           \u001b[38;5;34m1,180,160\u001b[0m \n",
       "\n",
       " batch_normalization_25           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)               \u001b[38;5;34m2,048\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)           \u001b[38;5;34m2,359,808\u001b[0m \n",
       "\n",
       " batch_normalization_26           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)               \u001b[38;5;34m2,048\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)           \u001b[38;5;34m2,359,808\u001b[0m \n",
       "\n",
       " batch_normalization_27           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)               \u001b[38;5;34m2,048\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout_11 (\u001b[38;5;33mDropout\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)                        \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_3 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                \u001b[38;5;34m4,719,616\u001b[0m \n",
       "\n",
       " batch_normalization_28           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                    \u001b[38;5;34m4,096\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " dropout_12 (\u001b[38;5;33mDropout\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                        \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_4 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                   \u001b[38;5;34m524,800\u001b[0m \n",
       "\n",
       " batch_normalization_29           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                     \u001b[38;5;34m2,048\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " dropout_13 (\u001b[38;5;33mDropout\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_5 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                     \u001b[38;5;34m10,260\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,081,460</span> (49.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,081,460\u001b[0m (49.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,072,628</span> (49.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,072,628\u001b[0m (49.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,832</span> (34.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m8,832\u001b[0m (34.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Set hyperparameters tuning\n",
    "optimizer = 'SGD'\n",
    "learning_rate = 0.0001\n",
    "dropout_rate = 0.2\n",
    "weight_decay = 0.0001\n",
    "momentum = 0.9\n",
    "clip_norm = 0.0\n",
    "num_classes = 20\n",
    "input_shape = INPUT_SHAPE\n",
    "\n",
    "def create_model(input_shape, num_classes, optimizer_name, learning_rate, dropout_rate, weight_decay, momentum, clip_norm):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Block 1\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Block 2\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Block 3\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Block 4\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Block 5\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Flatten\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Dense layers\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Define optimizer with hyperparameters\n",
    "    if optimizer_name == 'SGD':\n",
    "        optimizer = optimizers.SGD(learning_rate=learning_rate, decay=weight_decay, momentum=momentum, clipnorm=clip_norm)\n",
    "    elif optimizer_name == 'Adam':\n",
    "        optimizer = optimizers.Adam(learning_rate=learning_rate, decay=weight_decay, clipnorm=clip_norm)\n",
    "    elif optimizer_name == 'RMSprop':\n",
    "        optimizer = optimizers.RMSprop(learning_rate=learning_rate, decay=weight_decay, clipnorm=clip_norm)\n",
    "    else:\n",
    "        raise ValueError(\"Optimizer not supported. Choose from 'SGD', 'Adam', or 'RMSprop'.\")\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_model(input_shape=input_shape, num_classes=num_classes, optimizer_name=optimizer, learning_rate=learning_rate, \n",
    "                     dropout_rate=dropout_rate, weight_decay=weight_decay, momentum=momentum, clip_norm=clip_norm)\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4811539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.0561 - loss: 4.0732\n",
      "Epoch 1: Test Loss: 3.0421500205993652, Test Accuracy: 0.040183696895837784\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.0561 - loss: 4.0719 - learning_rate: 1.0000e-04 - epoch: 1.0000\n",
      "Epoch 2/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.0584 - loss: 3.8952\n",
      "Epoch 2: Test Loss: 3.121091604232788, Test Accuracy: 0.05740528181195259\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.0585 - loss: 3.8950 - learning_rate: 1.0000e-04 - epoch: 2.0000\n",
      "Epoch 3/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.0791 - loss: 3.7582\n",
      "Epoch 3: Test Loss: 3.5015792846679688, Test Accuracy: 0.04477611929178238\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.0791 - loss: 3.7575 - learning_rate: 1.0000e-04 - epoch: 3.0000\n",
      "Epoch 4/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1005 - loss: 3.6239\n",
      "Epoch 4: Test Loss: 3.746464252471924, Test Accuracy: 0.04477611929178238\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.1005 - loss: 3.6231 - learning_rate: 1.0000e-04 - epoch: 4.0000\n",
      "Epoch 5/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1111 - loss: 3.4473\n",
      "Epoch 5: Test Loss: 4.501121520996094, Test Accuracy: 0.04477611929178238\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.1113 - loss: 3.4465 - learning_rate: 1.0000e-04 - epoch: 5.0000\n",
      "Epoch 6/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1528 - loss: 3.2085\n",
      "Epoch 6: Test Loss: 5.327694416046143, Test Accuracy: 0.04477611929178238\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.1530 - loss: 3.2073 - learning_rate: 1.0000e-04 - epoch: 6.0000\n",
      "Epoch 7/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1651 - loss: 3.0469\n",
      "Epoch 7: Test Loss: 5.959114074707031, Test Accuracy: 0.04477611929178238\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.1654 - loss: 3.0456 - learning_rate: 1.0000e-04 - epoch: 7.0000\n",
      "Epoch 8/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2271 - loss: 2.7943\n",
      "Epoch 8: Test Loss: 6.244951248168945, Test Accuracy: 0.04477611929178238\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.2272 - loss: 2.7931 - learning_rate: 1.0000e-04 - epoch: 8.0000\n",
      "Epoch 9/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2752 - loss: 2.5572\n",
      "Epoch 9: Test Loss: 7.53924560546875, Test Accuracy: 0.043628014624118805\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.2750 - loss: 2.5575 - learning_rate: 1.0000e-04 - epoch: 9.0000\n",
      "Epoch 10/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2917 - loss: 2.4388\n",
      "Epoch 10: Test Loss: 8.305328369140625, Test Accuracy: 0.04477611929178238\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.2920 - loss: 2.4377 - learning_rate: 1.0000e-04 - epoch: 10.0000\n",
      "Epoch 11/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3428 - loss: 2.2386\n",
      "Epoch 11: Test Loss: 8.641953468322754, Test Accuracy: 0.04477611929178238\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3429 - loss: 2.2376 - learning_rate: 1.0000e-04 - epoch: 11.0000\n",
      "Epoch 12/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3890 - loss: 2.0698\n",
      "Epoch 12: Test Loss: 7.870519638061523, Test Accuracy: 0.04477611929178238\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.3890 - loss: 2.0694 - learning_rate: 1.0000e-04 - epoch: 12.0000\n",
      "Epoch 13/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4120 - loss: 1.9522\n",
      "Epoch 13: Test Loss: 6.580103397369385, Test Accuracy: 0.04592422395944595\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.4121 - loss: 1.9513 - learning_rate: 1.0000e-04 - epoch: 13.0000\n",
      "Epoch 14/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4547 - loss: 1.8092\n",
      "Epoch 14: Test Loss: 5.80933952331543, Test Accuracy: 0.06429391354322433\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.4547 - loss: 1.8091 - learning_rate: 1.0000e-04 - epoch: 14.0000\n",
      "Epoch 15/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4735 - loss: 1.7415\n",
      "Epoch 15: Test Loss: 5.411139488220215, Test Accuracy: 0.07118254899978638\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.4736 - loss: 1.7406 - learning_rate: 1.0000e-04 - epoch: 15.0000\n",
      "Epoch 16/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5199 - loss: 1.5811\n",
      "Epoch 16: Test Loss: 5.035277366638184, Test Accuracy: 0.09988518804311752\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.5198 - loss: 1.5809 - learning_rate: 1.0000e-04 - epoch: 16.0000\n",
      "Epoch 17/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5169 - loss: 1.5731\n",
      "Epoch 17: Test Loss: 4.65238618850708, Test Accuracy: 0.12169919908046722\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.5172 - loss: 1.5719 - learning_rate: 1.0000e-04 - epoch: 17.0000\n",
      "Epoch 18/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5599 - loss: 1.4170\n",
      "Epoch 18: Test Loss: 4.583500385284424, Test Accuracy: 0.1400688886642456\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.5598 - loss: 1.4173 - learning_rate: 1.0000e-04 - epoch: 18.0000\n",
      "Epoch 19/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5692 - loss: 1.3482\n",
      "Epoch 19: Test Loss: 4.345599174499512, Test Accuracy: 0.15499426424503326\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.5694 - loss: 1.3479 - learning_rate: 1.0000e-04 - epoch: 19.0000\n",
      "Epoch 20/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6000 - loss: 1.2588\n",
      "Epoch 20: Test Loss: 3.8008406162261963, Test Accuracy: 0.18714120984077454\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.6001 - loss: 1.2588 - learning_rate: 1.0000e-04 - epoch: 20.0000\n",
      "Epoch 21/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6182 - loss: 1.2133\n",
      "Epoch 21: Test Loss: 3.970696210861206, Test Accuracy: 0.18599310517311096\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.6183 - loss: 1.2132 - learning_rate: 1.0000e-04 - epoch: 21.0000\n",
      "Epoch 22/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6217 - loss: 1.1798\n",
      "Epoch 22: Test Loss: 3.9018542766571045, Test Accuracy: 0.19173364341259003\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.6220 - loss: 1.1794 - learning_rate: 1.0000e-04 - epoch: 22.0000\n",
      "Epoch 23/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6495 - loss: 1.1299\n",
      "Epoch 23: Test Loss: 4.15397834777832, Test Accuracy: 0.18599310517311096\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.6498 - loss: 1.1291 - learning_rate: 1.0000e-04 - epoch: 23.0000\n",
      "Epoch 24/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6453 - loss: 1.1165\n",
      "Epoch 24: Test Loss: 4.2219953536987305, Test Accuracy: 0.1710677444934845\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.6455 - loss: 1.1160 - learning_rate: 1.0000e-04 - epoch: 24.0000\n",
      "Epoch 25/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6680 - loss: 1.0417\n",
      "Epoch 25: Test Loss: 3.6707632541656494, Test Accuracy: 0.219288170337677\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.6682 - loss: 1.0413 - learning_rate: 1.0000e-04 - epoch: 25.0000\n",
      "Epoch 26/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7112 - loss: 0.9575\n",
      "Epoch 26: Test Loss: 3.4278266429901123, Test Accuracy: 0.24454650282859802\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.7110 - loss: 0.9578 - learning_rate: 1.0000e-04 - epoch: 26.0000\n",
      "Epoch 27/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6967 - loss: 0.9685\n",
      "Epoch 27: Test Loss: 3.523216724395752, Test Accuracy: 0.23765785992145538\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.6969 - loss: 0.9679 - learning_rate: 1.0000e-04 - epoch: 27.0000\n",
      "Epoch 28/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7235 - loss: 0.8748\n",
      "Epoch 28: Test Loss: 3.5134100914001465, Test Accuracy: 0.24339839816093445\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.7235 - loss: 0.8750 - learning_rate: 1.0000e-04 - epoch: 28.0000\n",
      "Epoch 29/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7305 - loss: 0.8363\n",
      "Epoch 29: Test Loss: 3.206449031829834, Test Accuracy: 0.27324914932250977\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.7306 - loss: 0.8362 - learning_rate: 1.0000e-04 - epoch: 29.0000\n",
      "Epoch 30/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7404 - loss: 0.8297\n",
      "Epoch 30: Test Loss: 3.5345547199249268, Test Accuracy: 0.2456946074962616\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.7403 - loss: 0.8297 - learning_rate: 1.0000e-04 - epoch: 30.0000\n",
      "Epoch 31/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7526 - loss: 0.8078\n",
      "Epoch 31: Test Loss: 3.3224117755889893, Test Accuracy: 0.2640642821788788\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.7526 - loss: 0.8078 - learning_rate: 1.0000e-04 - epoch: 31.0000\n",
      "Epoch 32/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7500 - loss: 0.8058\n",
      "Epoch 32: Test Loss: 3.0302698612213135, Test Accuracy: 0.2927669286727905\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.7500 - loss: 0.8053 - learning_rate: 1.0000e-04 - epoch: 32.0000\n",
      "Epoch 33/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7578 - loss: 0.7536\n",
      "Epoch 33: Test Loss: 3.016814947128296, Test Accuracy: 0.3065442144870758\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.7580 - loss: 0.7530 - learning_rate: 1.0000e-04 - epoch: 33.0000\n",
      "Epoch 34/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7625 - loss: 0.7401\n",
      "Epoch 34: Test Loss: 2.9592666625976562, Test Accuracy: 0.30884042382240295\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.7624 - loss: 0.7403 - learning_rate: 1.0000e-04 - epoch: 34.0000\n",
      "Epoch 35/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7843 - loss: 0.6750\n",
      "Epoch 35: Test Loss: 2.8519580364227295, Test Accuracy: 0.3237657845020294\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.7841 - loss: 0.6754 - learning_rate: 1.0000e-04 - epoch: 35.0000\n",
      "Epoch 36/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7936 - loss: 0.6607\n",
      "Epoch 36: Test Loss: 3.0656228065490723, Test Accuracy: 0.31343284249305725\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.7936 - loss: 0.6608 - learning_rate: 1.0000e-04 - epoch: 36.0000\n",
      "Epoch 37/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7779 - loss: 0.7020\n",
      "Epoch 37: Test Loss: 3.035468816757202, Test Accuracy: 0.3111366331577301\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.7780 - loss: 0.7014 - learning_rate: 1.0000e-04 - epoch: 37.0000\n",
      "Epoch 38/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8130 - loss: 0.6215\n",
      "Epoch 38: Test Loss: 2.868506669998169, Test Accuracy: 0.33180251717567444\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8130 - loss: 0.6216 - learning_rate: 1.0000e-04 - epoch: 38.0000\n",
      "Epoch 39/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7996 - loss: 0.6216\n",
      "Epoch 39: Test Loss: 2.8608765602111816, Test Accuracy: 0.3375430405139923\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.7996 - loss: 0.6216 - learning_rate: 1.0000e-04 - epoch: 39.0000\n",
      "Epoch 40/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8048 - loss: 0.6103\n",
      "Epoch 40: Test Loss: 2.460817575454712, Test Accuracy: 0.37543055415153503\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8046 - loss: 0.6107 - learning_rate: 1.0000e-04 - epoch: 40.0000\n",
      "Epoch 41/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8226 - loss: 0.5752\n",
      "Epoch 41: Test Loss: 2.7165234088897705, Test Accuracy: 0.35246843099594116\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8224 - loss: 0.5755 - learning_rate: 1.0000e-04 - epoch: 41.0000\n",
      "Epoch 42/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8211 - loss: 0.5557\n",
      "Epoch 42: Test Loss: 2.842106580734253, Test Accuracy: 0.342135488986969\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8210 - loss: 0.5562 - learning_rate: 1.0000e-04 - epoch: 42.0000\n",
      "Epoch 43/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8253 - loss: 0.5448\n",
      "Epoch 43: Test Loss: 2.442249059677124, Test Accuracy: 0.3811710774898529\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8253 - loss: 0.5449 - learning_rate: 1.0000e-04 - epoch: 43.0000\n",
      "Epoch 44/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8182 - loss: 0.5536\n",
      "Epoch 44: Test Loss: 2.408559560775757, Test Accuracy: 0.38346728682518005\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8183 - loss: 0.5535 - learning_rate: 1.0000e-04 - epoch: 44.0000\n",
      "Epoch 45/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8332 - loss: 0.5284\n",
      "Epoch 45: Test Loss: 2.500666856765747, Test Accuracy: 0.3742824196815491\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8333 - loss: 0.5282 - learning_rate: 1.0000e-04 - epoch: 45.0000\n",
      "Epoch 46/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8390 - loss: 0.5157\n",
      "Epoch 46: Test Loss: 2.4175682067871094, Test Accuracy: 0.38461539149284363\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8391 - loss: 0.5157 - learning_rate: 1.0000e-04 - epoch: 46.0000\n",
      "Epoch 47/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8481 - loss: 0.4872\n",
      "Epoch 47: Test Loss: 2.4197888374328613, Test Accuracy: 0.3892078101634979\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8480 - loss: 0.4872 - learning_rate: 1.0000e-04 - epoch: 47.0000\n",
      "Epoch 48/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8401 - loss: 0.5067\n",
      "Epoch 48: Test Loss: 2.545325756072998, Test Accuracy: 0.3857634961605072\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8402 - loss: 0.5065 - learning_rate: 1.0000e-04 - epoch: 48.0000\n",
      "Epoch 49/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8531 - loss: 0.4750\n",
      "Epoch 49: Test Loss: 2.632375717163086, Test Accuracy: 0.36624568700790405\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8531 - loss: 0.4749 - learning_rate: 1.0000e-04 - epoch: 49.0000\n",
      "Epoch 50/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8507 - loss: 0.4678\n",
      "Epoch 50: Test Loss: 2.5833897590637207, Test Accuracy: 0.3811710774898529\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8507 - loss: 0.4678 - learning_rate: 1.0000e-04 - epoch: 50.0000\n",
      "Epoch 51/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8466 - loss: 0.4567\n",
      "Epoch 51: Test Loss: 2.5385091304779053, Test Accuracy: 0.3949483335018158\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8469 - loss: 0.4565 - learning_rate: 1.0000e-04 - epoch: 51.0000\n",
      "Epoch 52/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8739 - loss: 0.4270\n",
      "Epoch 52: Test Loss: 2.2481582164764404, Test Accuracy: 0.4213547706604004\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8738 - loss: 0.4272 - learning_rate: 1.0000e-04 - epoch: 52.0000\n",
      "Epoch 53/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8527 - loss: 0.4419\n",
      "Epoch 53: Test Loss: 2.122889995574951, Test Accuracy: 0.44546496868133545\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8527 - loss: 0.4420 - learning_rate: 1.0000e-04 - epoch: 53.0000\n",
      "Epoch 54/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8644 - loss: 0.4249\n",
      "Epoch 54: Test Loss: 2.0910489559173584, Test Accuracy: 0.4592422544956207\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8644 - loss: 0.4250 - learning_rate: 1.0000e-04 - epoch: 54.0000\n",
      "Epoch 55/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8577 - loss: 0.4280\n",
      "Epoch 55: Test Loss: 2.208993673324585, Test Accuracy: 0.447761207818985\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8578 - loss: 0.4280 - learning_rate: 1.0000e-04 - epoch: 55.0000\n",
      "Epoch 56/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8816 - loss: 0.4155\n",
      "Epoch 56: Test Loss: 2.324573278427124, Test Accuracy: 0.4293915033340454\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8816 - loss: 0.4153 - learning_rate: 1.0000e-04 - epoch: 56.0000\n",
      "Epoch 57/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8668 - loss: 0.4190\n",
      "Epoch 57: Test Loss: 2.081111431121826, Test Accuracy: 0.45809414982795715\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8669 - loss: 0.4188 - learning_rate: 1.0000e-04 - epoch: 57.0000\n",
      "Epoch 58/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8879 - loss: 0.3648\n",
      "Epoch 58: Test Loss: 2.2633237838745117, Test Accuracy: 0.4443168640136719\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8878 - loss: 0.3651 - learning_rate: 1.0000e-04 - epoch: 58.0000\n",
      "Epoch 59/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8854 - loss: 0.3751\n",
      "Epoch 59: Test Loss: 1.8413223028182983, Test Accuracy: 0.48450058698654175\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8854 - loss: 0.3751 - learning_rate: 1.0000e-04 - epoch: 59.0000\n",
      "Epoch 60/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8832 - loss: 0.3737\n",
      "Epoch 60: Test Loss: 1.955692172050476, Test Accuracy: 0.4730195105075836\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8832 - loss: 0.3737 - learning_rate: 1.0000e-04 - epoch: 60.0000\n",
      "Epoch 61/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8807 - loss: 0.3831\n",
      "Epoch 61: Test Loss: 2.274250030517578, Test Accuracy: 0.44087255001068115\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8807 - loss: 0.3829 - learning_rate: 1.0000e-04 - epoch: 61.0000\n",
      "Epoch 62/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8985 - loss: 0.3344\n",
      "Epoch 62: Test Loss: 2.347837209701538, Test Accuracy: 0.42365097999572754\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.8984 - loss: 0.3346 - learning_rate: 1.0000e-04 - epoch: 62.0000\n",
      "Epoch 63/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8840 - loss: 0.3484\n",
      "Epoch 63: Test Loss: 2.1199309825897217, Test Accuracy: 0.45579794049263\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8840 - loss: 0.3484 - learning_rate: 1.0000e-04 - epoch: 63.0000\n",
      "Epoch 64/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8831 - loss: 0.3612\n",
      "Epoch 64: Test Loss: 1.900357723236084, Test Accuracy: 0.4867967963218689\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8832 - loss: 0.3609 - learning_rate: 1.0000e-04 - epoch: 64.0000\n",
      "Epoch 65/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8899 - loss: 0.3508\n",
      "Epoch 65: Test Loss: 2.0790443420410156, Test Accuracy: 0.4695751965045929\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.8900 - loss: 0.3507 - learning_rate: 1.0000e-04 - epoch: 65.0000\n",
      "Epoch 66/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8993 - loss: 0.3356\n",
      "Epoch 66: Test Loss: 1.9317960739135742, Test Accuracy: 0.4867967963218689\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.8994 - loss: 0.3352 - learning_rate: 1.0000e-04 - epoch: 66.0000\n",
      "Epoch 67/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8868 - loss: 0.3601\n",
      "Epoch 67: Test Loss: 1.9658180475234985, Test Accuracy: 0.4833524823188782\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8868 - loss: 0.3600 - learning_rate: 1.0000e-04 - epoch: 67.0000\n",
      "Epoch 68/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8915 - loss: 0.3298\n",
      "Epoch 68: Test Loss: 1.9680722951889038, Test Accuracy: 0.4787600338459015\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8915 - loss: 0.3298 - learning_rate: 1.0000e-04 - epoch: 68.0000\n",
      "Epoch 69/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8948 - loss: 0.3264\n",
      "Epoch 69: Test Loss: 1.8302719593048096, Test Accuracy: 0.49827784299850464\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8949 - loss: 0.3263 - learning_rate: 1.0000e-04 - epoch: 69.0000\n",
      "Epoch 70/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8994 - loss: 0.3104\n",
      "Epoch 70: Test Loss: 2.0975887775421143, Test Accuracy: 0.4649827778339386\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8994 - loss: 0.3106 - learning_rate: 1.0000e-04 - epoch: 70.0000\n",
      "Epoch 71/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8962 - loss: 0.3299\n",
      "Epoch 71: Test Loss: 1.8394842147827148, Test Accuracy: 0.49253731966018677\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8962 - loss: 0.3297 - learning_rate: 1.0000e-04 - epoch: 71.0000\n",
      "Epoch 72/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8988 - loss: 0.3190\n",
      "Epoch 72: Test Loss: 1.687361240386963, Test Accuracy: 0.5154994130134583\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.8988 - loss: 0.3190 - learning_rate: 1.0000e-04 - epoch: 72.0000\n",
      "Epoch 73/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9117 - loss: 0.2821\n",
      "Epoch 73: Test Loss: 1.9103091955184937, Test Accuracy: 0.49253731966018677\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9116 - loss: 0.2825 - learning_rate: 1.0000e-04 - epoch: 73.0000\n",
      "Epoch 74/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9110 - loss: 0.2695\n",
      "Epoch 74: Test Loss: 1.8093349933624268, Test Accuracy: 0.5017221570014954\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9109 - loss: 0.2698 - learning_rate: 1.0000e-04 - epoch: 74.0000\n",
      "Epoch 75/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9059 - loss: 0.2827\n",
      "Epoch 75: Test Loss: 1.7664111852645874, Test Accuracy: 0.5005740523338318\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9060 - loss: 0.2825 - learning_rate: 1.0000e-04 - epoch: 75.0000\n",
      "Epoch 76/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9157 - loss: 0.2643\n",
      "Epoch 76: Test Loss: 1.6654596328735352, Test Accuracy: 0.518943727016449\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9155 - loss: 0.2646 - learning_rate: 1.0000e-04 - epoch: 76.0000\n",
      "Epoch 77/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9001 - loss: 0.2980\n",
      "Epoch 77: Test Loss: 1.7578884363174438, Test Accuracy: 0.5200918316841125\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9001 - loss: 0.2979 - learning_rate: 1.0000e-04 - epoch: 77.0000\n",
      "Epoch 78/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9183 - loss: 0.2763\n",
      "Epoch 78: Test Loss: 1.9068483114242554, Test Accuracy: 0.49253731966018677\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9183 - loss: 0.2763 - learning_rate: 1.0000e-04 - epoch: 78.0000\n",
      "Epoch 79/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9123 - loss: 0.2671\n",
      "Epoch 79: Test Loss: 1.4880433082580566, Test Accuracy: 0.5522388219833374\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9123 - loss: 0.2671 - learning_rate: 1.0000e-04 - epoch: 79.0000\n",
      "Epoch 80/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9147 - loss: 0.2745\n",
      "Epoch 80: Test Loss: 1.8014336824417114, Test Accuracy: 0.5051664710044861\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9148 - loss: 0.2742 - learning_rate: 1.0000e-04 - epoch: 80.0000\n",
      "Epoch 81/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9292 - loss: 0.2380\n",
      "Epoch 81: Test Loss: 1.9008994102478027, Test Accuracy: 0.5040183663368225\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.9292 - loss: 0.2381 - learning_rate: 1.0000e-04 - epoch: 81.0000\n",
      "Epoch 82/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9241 - loss: 0.2503\n",
      "Epoch 82: Test Loss: 1.7026392221450806, Test Accuracy: 0.5258323550224304\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9240 - loss: 0.2506 - learning_rate: 1.0000e-04 - epoch: 82.0000\n",
      "Epoch 83/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9270 - loss: 0.2400\n",
      "Epoch 83: Test Loss: 1.6391640901565552, Test Accuracy: 0.5373134613037109\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9269 - loss: 0.2403 - learning_rate: 1.0000e-04 - epoch: 83.0000\n",
      "Epoch 84/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9118 - loss: 0.2679\n",
      "Epoch 84: Test Loss: 1.4432874917984009, Test Accuracy: 0.577497124671936\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9120 - loss: 0.2677 - learning_rate: 1.0000e-04 - epoch: 84.0000\n",
      "Epoch 85/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9239 - loss: 0.2412\n",
      "Epoch 85: Test Loss: 1.6267716884613037, Test Accuracy: 0.5487945079803467\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9239 - loss: 0.2414 - learning_rate: 1.0000e-04 - epoch: 85.0000\n",
      "Epoch 86/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9259 - loss: 0.2419\n",
      "Epoch 86: Test Loss: 1.6826587915420532, Test Accuracy: 0.5384615659713745\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9258 - loss: 0.2420 - learning_rate: 1.0000e-04 - epoch: 86.0000\n",
      "Epoch 87/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9291 - loss: 0.2477\n",
      "Epoch 87: Test Loss: 1.7729675769805908, Test Accuracy: 0.5223880410194397\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9290 - loss: 0.2478 - learning_rate: 1.0000e-04 - epoch: 87.0000\n",
      "Epoch 88/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9165 - loss: 0.2594\n",
      "Epoch 88: Test Loss: 1.6712713241577148, Test Accuracy: 0.5407577753067017\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9167 - loss: 0.2591 - learning_rate: 1.0000e-04 - epoch: 88.0000\n",
      "Epoch 89/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9248 - loss: 0.2475\n",
      "Epoch 89: Test Loss: 1.6793242692947388, Test Accuracy: 0.5373134613037109\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9248 - loss: 0.2473 - learning_rate: 1.0000e-04 - epoch: 89.0000\n",
      "Epoch 90/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9281 - loss: 0.2272\n",
      "Epoch 90: Test Loss: 1.5523372888565063, Test Accuracy: 0.5660160779953003\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9280 - loss: 0.2272 - learning_rate: 1.0000e-04 - epoch: 90.0000\n",
      "Epoch 91/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9395 - loss: 0.2008\n",
      "Epoch 91: Test Loss: 1.4940059185028076, Test Accuracy: 0.5660160779953003\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9394 - loss: 0.2012 - learning_rate: 1.0000e-04 - epoch: 91.0000\n",
      "Epoch 92/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9346 - loss: 0.2031\n",
      "Epoch 92: Test Loss: 1.5228782892227173, Test Accuracy: 0.5637198686599731\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9345 - loss: 0.2033 - learning_rate: 1.0000e-04 - epoch: 92.0000\n",
      "Epoch 93/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9297 - loss: 0.2163\n",
      "Epoch 93: Test Loss: 1.6124851703643799, Test Accuracy: 0.5407577753067017\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9297 - loss: 0.2164 - learning_rate: 1.0000e-04 - epoch: 93.0000\n",
      "Epoch 94/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9283 - loss: 0.2279\n",
      "Epoch 94: Test Loss: 1.471571922302246, Test Accuracy: 0.5706084966659546\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9283 - loss: 0.2277 - learning_rate: 1.0000e-04 - epoch: 94.0000\n",
      "Epoch 95/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9285 - loss: 0.2299\n",
      "Epoch 95: Test Loss: 1.3798243999481201, Test Accuracy: 0.5912743806838989\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9286 - loss: 0.2299 - learning_rate: 1.0000e-04 - epoch: 95.0000\n",
      "Epoch 96/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9337 - loss: 0.2077\n",
      "Epoch 96: Test Loss: 1.570461392402649, Test Accuracy: 0.5545350313186646\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9337 - loss: 0.2079 - learning_rate: 1.0000e-04 - epoch: 96.0000\n",
      "Epoch 97/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9368 - loss: 0.2127\n",
      "Epoch 97: Test Loss: 1.550210952758789, Test Accuracy: 0.5545350313186646\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9368 - loss: 0.2127 - learning_rate: 1.0000e-04 - epoch: 97.0000\n",
      "Epoch 98/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9433 - loss: 0.1788\n",
      "Epoch 98: Test Loss: 1.3543838262557983, Test Accuracy: 0.6061997413635254\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9433 - loss: 0.1790 - learning_rate: 1.0000e-04 - epoch: 98.0000\n",
      "Epoch 99/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9342 - loss: 0.2007\n",
      "Epoch 99: Test Loss: 1.544622778892517, Test Accuracy: 0.5637198686599731\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9342 - loss: 0.2008 - learning_rate: 1.0000e-04 - epoch: 99.0000\n",
      "Epoch 100/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9387 - loss: 0.1984\n",
      "Epoch 100: Test Loss: 1.6207269430160522, Test Accuracy: 0.5487945079803467\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9387 - loss: 0.1984 - learning_rate: 1.0000e-04 - epoch: 100.0000\n",
      "Epoch 101/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9365 - loss: 0.2079\n",
      "Epoch 101: Test Loss: 1.521809697151184, Test Accuracy: 0.577497124671936\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9365 - loss: 0.2078 - learning_rate: 1.0000e-04 - epoch: 101.0000\n",
      "Epoch 102/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9420 - loss: 0.1948\n",
      "Epoch 102: Test Loss: 1.452146291732788, Test Accuracy: 0.585533857345581\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9420 - loss: 0.1947 - learning_rate: 1.0000e-04 - epoch: 102.0000\n",
      "Epoch 103/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9424 - loss: 0.1971\n",
      "Epoch 103: Test Loss: 1.3719192743301392, Test Accuracy: 0.6004592180252075\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9424 - loss: 0.1972 - learning_rate: 1.0000e-04 - epoch: 103.0000\n",
      "Epoch 104/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9445 - loss: 0.1955\n",
      "Epoch 104: Test Loss: 1.2351512908935547, Test Accuracy: 0.641791045665741\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9445 - loss: 0.1953 - learning_rate: 1.0000e-04 - epoch: 104.0000\n",
      "Epoch 105/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9498 - loss: 0.1675\n",
      "Epoch 105: Test Loss: 1.5026118755340576, Test Accuracy: 0.5809414386749268\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9497 - loss: 0.1678 - learning_rate: 1.0000e-04 - epoch: 105.0000\n",
      "Epoch 106/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9504 - loss: 0.1798\n",
      "Epoch 106: Test Loss: 1.2051434516906738, Test Accuracy: 0.6486796736717224\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9503 - loss: 0.1798 - learning_rate: 1.0000e-04 - epoch: 106.0000\n",
      "Epoch 107/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9467 - loss: 0.1930\n",
      "Epoch 107: Test Loss: 1.1798256635665894, Test Accuracy: 0.6590126156806946\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9467 - loss: 0.1929 - learning_rate: 1.0000e-04 - epoch: 107.0000\n",
      "Epoch 108/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9483 - loss: 0.1708\n",
      "Epoch 108: Test Loss: 1.2211556434631348, Test Accuracy: 0.633754312992096\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9481 - loss: 0.1709 - learning_rate: 1.0000e-04 - epoch: 108.0000\n",
      "Epoch 109/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9507 - loss: 0.1676\n",
      "Epoch 109: Test Loss: 1.176089882850647, Test Accuracy: 0.6590126156806946\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9506 - loss: 0.1677 - learning_rate: 1.0000e-04 - epoch: 109.0000\n",
      "Epoch 110/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9494 - loss: 0.1630\n",
      "Epoch 110: Test Loss: 1.366539716720581, Test Accuracy: 0.6039035320281982\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9494 - loss: 0.1631 - learning_rate: 1.0000e-04 - epoch: 110.0000\n",
      "Epoch 111/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9485 - loss: 0.1710\n",
      "Epoch 111: Test Loss: 1.2033385038375854, Test Accuracy: 0.6463834643363953\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9485 - loss: 0.1710 - learning_rate: 1.0000e-04 - epoch: 111.0000\n",
      "Epoch 112/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9509 - loss: 0.1757\n",
      "Epoch 112: Test Loss: 1.15384840965271, Test Accuracy: 0.6567164063453674\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9508 - loss: 0.1755 - learning_rate: 1.0000e-04 - epoch: 112.0000\n",
      "Epoch 113/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9519 - loss: 0.1658\n",
      "Epoch 113: Test Loss: 1.1909998655319214, Test Accuracy: 0.6521239876747131\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9519 - loss: 0.1658 - learning_rate: 1.0000e-04 - epoch: 113.0000\n",
      "Epoch 114/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9525 - loss: 0.1645\n",
      "Epoch 114: Test Loss: 1.1887495517730713, Test Accuracy: 0.6509758830070496\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9524 - loss: 0.1646 - learning_rate: 1.0000e-04 - epoch: 114.0000\n",
      "Epoch 115/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9452 - loss: 0.1584\n",
      "Epoch 115: Test Loss: 1.235695242881775, Test Accuracy: 0.6371986269950867\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9452 - loss: 0.1585 - learning_rate: 1.0000e-04 - epoch: 115.0000\n",
      "Epoch 116/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9454 - loss: 0.1696\n",
      "Epoch 116: Test Loss: 1.2055741548538208, Test Accuracy: 0.6567164063453674\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9454 - loss: 0.1696 - learning_rate: 1.0000e-04 - epoch: 116.0000\n",
      "Epoch 117/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9570 - loss: 0.1519\n",
      "Epoch 117: Test Loss: 1.2195581197738647, Test Accuracy: 0.649827778339386\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9570 - loss: 0.1520 - learning_rate: 1.0000e-04 - epoch: 117.0000\n",
      "Epoch 118/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9422 - loss: 0.1720\n",
      "Epoch 118: Test Loss: 1.2090476751327515, Test Accuracy: 0.649827778339386\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9423 - loss: 0.1719 - learning_rate: 1.0000e-04 - epoch: 118.0000\n",
      "Epoch 119/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9454 - loss: 0.1725\n",
      "Epoch 119: Test Loss: 1.1590200662612915, Test Accuracy: 0.6532720923423767\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.9454 - loss: 0.1724 - learning_rate: 1.0000e-04 - epoch: 119.0000\n",
      "Epoch 120/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9570 - loss: 0.1513\n",
      "Epoch 120: Test Loss: 1.4027942419052124, Test Accuracy: 0.611940324306488\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.9570 - loss: 0.1513 - learning_rate: 1.0000e-04 - epoch: 120.0000\n",
      "Epoch 121/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9599 - loss: 0.1521\n",
      "Epoch 121: Test Loss: 1.482856035232544, Test Accuracy: 0.5981630086898804\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9598 - loss: 0.1520 - learning_rate: 1.0000e-04 - epoch: 121.0000\n",
      "Epoch 122/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9526 - loss: 0.1507\n",
      "Epoch 122: Test Loss: 1.3747471570968628, Test Accuracy: 0.6188289523124695\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9526 - loss: 0.1509 - learning_rate: 1.0000e-04 - epoch: 122.0000\n",
      "Epoch 123/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9619 - loss: 0.1373\n",
      "Epoch 123: Test Loss: 1.2276356220245361, Test Accuracy: 0.6475315690040588\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9618 - loss: 0.1375 - learning_rate: 1.0000e-04 - epoch: 123.0000\n",
      "Epoch 124/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9572 - loss: 0.1443\n",
      "Epoch 124: Test Loss: 1.4392980337142944, Test Accuracy: 0.6039035320281982\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9571 - loss: 0.1444 - learning_rate: 1.0000e-04 - epoch: 124.0000\n",
      "Epoch 125/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9542 - loss: 0.1481\n",
      "Epoch 125: Test Loss: 1.220202922821045, Test Accuracy: 0.6463834643363953\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9541 - loss: 0.1481 - learning_rate: 1.0000e-04 - epoch: 125.0000\n",
      "Epoch 126/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9593 - loss: 0.1473\n",
      "Epoch 126: Test Loss: 1.1350897550582886, Test Accuracy: 0.6762341856956482\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9593 - loss: 0.1473 - learning_rate: 1.0000e-04 - epoch: 126.0000\n",
      "Epoch 127/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9470 - loss: 0.1673\n",
      "Epoch 127: Test Loss: 1.0832688808441162, Test Accuracy: 0.6934558153152466\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9471 - loss: 0.1670 - learning_rate: 1.0000e-04 - epoch: 127.0000\n",
      "Epoch 128/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9562 - loss: 0.1432\n",
      "Epoch 128: Test Loss: 1.0705488920211792, Test Accuracy: 0.692307710647583\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.9562 - loss: 0.1431 - learning_rate: 1.0000e-04 - epoch: 128.0000\n",
      "Epoch 129/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9612 - loss: 0.1365\n",
      "Epoch 129: Test Loss: 1.1231893301010132, Test Accuracy: 0.6716417670249939\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9611 - loss: 0.1365 - learning_rate: 1.0000e-04 - epoch: 129.0000\n",
      "Epoch 130/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9621 - loss: 0.1305\n",
      "Epoch 130: Test Loss: 1.24734628200531, Test Accuracy: 0.6452353596687317\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9620 - loss: 0.1306 - learning_rate: 1.0000e-04 - epoch: 130.0000\n",
      "Epoch 131/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9602 - loss: 0.1427\n",
      "Epoch 131: Test Loss: 1.1892096996307373, Test Accuracy: 0.6613088250160217\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9602 - loss: 0.1427 - learning_rate: 1.0000e-04 - epoch: 131.0000\n",
      "Epoch 132/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9565 - loss: 0.1452\n",
      "Epoch 132: Test Loss: 1.1875871419906616, Test Accuracy: 0.6647531390190125\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9565 - loss: 0.1453 - learning_rate: 1.0000e-04 - epoch: 132.0000\n",
      "Epoch 133/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9547 - loss: 0.1511\n",
      "Epoch 133: Test Loss: 1.2097558975219727, Test Accuracy: 0.6613088250160217\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.9548 - loss: 0.1508 - learning_rate: 1.0000e-04 - epoch: 133.0000\n",
      "Epoch 134/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9533 - loss: 0.1515\n",
      "Epoch 134: Test Loss: 1.2097208499908447, Test Accuracy: 0.6544201970100403\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9534 - loss: 0.1513 - learning_rate: 1.0000e-04 - epoch: 134.0000\n",
      "Epoch 135/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9541 - loss: 0.1536\n",
      "Epoch 135: Test Loss: 1.1630163192749023, Test Accuracy: 0.6693455576896667\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.9541 - loss: 0.1534 - learning_rate: 1.0000e-04 - epoch: 135.0000\n",
      "Epoch 136/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9563 - loss: 0.1408\n",
      "Epoch 136: Test Loss: 1.0494979619979858, Test Accuracy: 0.7049368619918823\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9563 - loss: 0.1408 - learning_rate: 1.0000e-04 - epoch: 136.0000\n",
      "Epoch 137/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9629 - loss: 0.1258\n",
      "Epoch 137: Test Loss: 1.0142840147018433, Test Accuracy: 0.708381175994873\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9628 - loss: 0.1258 - learning_rate: 1.0000e-04 - epoch: 137.0000\n",
      "Epoch 138/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9624 - loss: 0.1258\n",
      "Epoch 138: Test Loss: 1.0997319221496582, Test Accuracy: 0.6911596059799194\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9624 - loss: 0.1259 - learning_rate: 1.0000e-04 - epoch: 138.0000\n",
      "Epoch 139/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9599 - loss: 0.1266\n",
      "Epoch 139: Test Loss: 1.134819507598877, Test Accuracy: 0.6750860810279846\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9600 - loss: 0.1266 - learning_rate: 1.0000e-04 - epoch: 139.0000\n",
      "Epoch 140/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9628 - loss: 0.1160\n",
      "Epoch 140: Test Loss: 1.0448929071426392, Test Accuracy: 0.6991963386535645\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9628 - loss: 0.1162 - learning_rate: 1.0000e-04 - epoch: 140.0000\n",
      "Epoch 141/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9605 - loss: 0.1265\n",
      "Epoch 141: Test Loss: 1.1995759010314941, Test Accuracy: 0.6567164063453674\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9604 - loss: 0.1265 - learning_rate: 1.0000e-04 - epoch: 141.0000\n",
      "Epoch 142/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9580 - loss: 0.1344\n",
      "Epoch 142: Test Loss: 0.9767850637435913, Test Accuracy: 0.7221584320068359\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.9581 - loss: 0.1343 - learning_rate: 1.0000e-04 - epoch: 142.0000\n",
      "Epoch 143/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9669 - loss: 0.1155\n",
      "Epoch 143: Test Loss: 1.1168761253356934, Test Accuracy: 0.6854190826416016\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.9668 - loss: 0.1155 - learning_rate: 1.0000e-04 - epoch: 143.0000\n",
      "Epoch 144/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9661 - loss: 0.1170\n",
      "Epoch 144: Test Loss: 1.1854474544525146, Test Accuracy: 0.6681974530220032\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9661 - loss: 0.1171 - learning_rate: 1.0000e-04 - epoch: 144.0000\n",
      "Epoch 145/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9686 - loss: 0.1184\n",
      "Epoch 145: Test Loss: 1.0804954767227173, Test Accuracy: 0.6888633966445923\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9685 - loss: 0.1185 - learning_rate: 1.0000e-04 - epoch: 145.0000\n",
      "Epoch 146/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9789 - loss: 0.0962\n",
      "Epoch 146: Test Loss: 1.0697818994522095, Test Accuracy: 0.692307710647583\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.9787 - loss: 0.0964 - learning_rate: 1.0000e-04 - epoch: 146.0000\n",
      "Epoch 147/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9678 - loss: 0.1095\n",
      "Epoch 147: Test Loss: 1.038772702217102, Test Accuracy: 0.6991963386535645\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9677 - loss: 0.1097 - learning_rate: 1.0000e-04 - epoch: 147.0000\n",
      "Epoch 148/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9655 - loss: 0.1210\n",
      "Epoch 148: Test Loss: 0.9962354302406311, Test Accuracy: 0.7118254899978638\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9656 - loss: 0.1209 - learning_rate: 1.0000e-04 - epoch: 148.0000\n",
      "Epoch 149/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9701 - loss: 0.1192\n",
      "Epoch 149: Test Loss: 1.1175464391708374, Test Accuracy: 0.6819747686386108\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9701 - loss: 0.1191 - learning_rate: 1.0000e-04 - epoch: 149.0000\n",
      "Epoch 150/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9733 - loss: 0.0964\n",
      "Epoch 150: Test Loss: 1.0726592540740967, Test Accuracy: 0.6865671873092651\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.9732 - loss: 0.0966 - learning_rate: 1.0000e-04 - epoch: 150.0000\n",
      "Epoch 151/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9558 - loss: 0.1304\n",
      "Epoch 151: Test Loss: 1.1201951503753662, Test Accuracy: 0.6750860810279846\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9559 - loss: 0.1303 - learning_rate: 1.0000e-04 - epoch: 151.0000\n",
      "Epoch 152/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9655 - loss: 0.1233\n",
      "Epoch 152: Test Loss: 1.0217938423156738, Test Accuracy: 0.708381175994873\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9655 - loss: 0.1231 - learning_rate: 1.0000e-04 - epoch: 152.0000\n",
      "Epoch 153/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9724 - loss: 0.1096\n",
      "Epoch 153: Test Loss: 0.9986168742179871, Test Accuracy: 0.7118254899978638\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.9724 - loss: 0.1097 - learning_rate: 1.0000e-04 - epoch: 153.0000\n",
      "Epoch 154/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9663 - loss: 0.1085\n",
      "Epoch 154: Test Loss: 0.9740122556686401, Test Accuracy: 0.7233065366744995\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.9663 - loss: 0.1086 - learning_rate: 1.0000e-04 - epoch: 154.0000\n",
      "Epoch 155/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9720 - loss: 0.1043\n",
      "Epoch 155: Test Loss: 0.9659408926963806, Test Accuracy: 0.7233065366744995\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.9720 - loss: 0.1043 - learning_rate: 1.0000e-04 - epoch: 155.0000\n",
      "Epoch 156/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9693 - loss: 0.1088\n",
      "Epoch 156: Test Loss: 0.9491409063339233, Test Accuracy: 0.7290470600128174\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 0.9693 - loss: 0.1088 - learning_rate: 1.0000e-04 - epoch: 156.0000\n",
      "Epoch 157/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9746 - loss: 0.0955\n",
      "Epoch 157: Test Loss: 1.0947896242141724, Test Accuracy: 0.6854190826416016\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.9746 - loss: 0.0957 - learning_rate: 1.0000e-04 - epoch: 157.0000\n",
      "Epoch 158/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9690 - loss: 0.1144\n",
      "Epoch 158: Test Loss: 0.8575649857521057, Test Accuracy: 0.7543054223060608\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9689 - loss: 0.1145 - learning_rate: 1.0000e-04 - epoch: 158.0000\n",
      "Epoch 159/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9666 - loss: 0.1123\n",
      "Epoch 159: Test Loss: 0.9357215166091919, Test Accuracy: 0.7324913740158081\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9666 - loss: 0.1124 - learning_rate: 1.0000e-04 - epoch: 159.0000\n",
      "Epoch 160/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9731 - loss: 0.0968\n",
      "Epoch 160: Test Loss: 0.8957041501998901, Test Accuracy: 0.7405281066894531\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9731 - loss: 0.0970 - learning_rate: 1.0000e-04 - epoch: 160.0000\n",
      "Epoch 161/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9718 - loss: 0.0986\n",
      "Epoch 161: Test Loss: 0.8870166540145874, Test Accuracy: 0.7439724206924438\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.9717 - loss: 0.0987 - learning_rate: 1.0000e-04 - epoch: 161.0000\n",
      "Epoch 162/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9675 - loss: 0.1038\n",
      "Epoch 162: Test Loss: 0.9504201412200928, Test Accuracy: 0.7267508506774902\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9675 - loss: 0.1039 - learning_rate: 1.0000e-04 - epoch: 162.0000\n",
      "Epoch 163/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9706 - loss: 0.1055\n",
      "Epoch 163: Test Loss: 0.9567105174064636, Test Accuracy: 0.7233065366744995\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9706 - loss: 0.1054 - learning_rate: 1.0000e-04 - epoch: 163.0000\n",
      "Epoch 164/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9778 - loss: 0.0934\n",
      "Epoch 164: Test Loss: 0.8271874189376831, Test Accuracy: 0.7554535269737244\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.9777 - loss: 0.0935 - learning_rate: 1.0000e-04 - epoch: 164.0000\n",
      "Epoch 165/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9723 - loss: 0.1030\n",
      "Epoch 165: Test Loss: 0.8109895586967468, Test Accuracy: 0.7623421549797058\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9723 - loss: 0.1030 - learning_rate: 1.0000e-04 - epoch: 165.0000\n",
      "Epoch 166/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9708 - loss: 0.0975\n",
      "Epoch 166: Test Loss: 0.9280063509941101, Test Accuracy: 0.738231897354126\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9708 - loss: 0.0975 - learning_rate: 1.0000e-04 - epoch: 166.0000\n",
      "Epoch 167/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9748 - loss: 0.0950\n",
      "Epoch 167: Test Loss: 0.946726381778717, Test Accuracy: 0.7405281066894531\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - accuracy: 0.9748 - loss: 0.0950 - learning_rate: 1.0000e-04 - epoch: 167.0000\n",
      "Epoch 168/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9678 - loss: 0.1111\n",
      "Epoch 168: Test Loss: 0.957720935344696, Test Accuracy: 0.7336394786834717\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - accuracy: 0.9678 - loss: 0.1110 - learning_rate: 1.0000e-04 - epoch: 168.0000\n",
      "Epoch 169/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9698 - loss: 0.0970\n",
      "Epoch 169: Test Loss: 0.944410502910614, Test Accuracy: 0.7221584320068359\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - accuracy: 0.9698 - loss: 0.0970 - learning_rate: 1.0000e-04 - epoch: 169.0000\n",
      "Epoch 170/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9765 - loss: 0.0881\n",
      "Epoch 170: Test Loss: 0.8692734241485596, Test Accuracy: 0.7531573176383972\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - accuracy: 0.9765 - loss: 0.0882 - learning_rate: 1.0000e-04 - epoch: 170.0000\n",
      "Epoch 171/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9720 - loss: 0.0971\n",
      "Epoch 171: Test Loss: 0.8311771750450134, Test Accuracy: 0.7600459456443787\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - accuracy: 0.9720 - loss: 0.0972 - learning_rate: 1.0000e-04 - epoch: 171.0000\n",
      "Epoch 172/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9769 - loss: 0.0856\n",
      "Epoch 172: Test Loss: 0.9210358262062073, Test Accuracy: 0.7324913740158081\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - accuracy: 0.9768 - loss: 0.0856 - learning_rate: 1.0000e-04 - epoch: 172.0000\n",
      "Epoch 173/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9747 - loss: 0.1011\n",
      "Epoch 173: Test Loss: 0.9249573349952698, Test Accuracy: 0.7370837926864624\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - accuracy: 0.9746 - loss: 0.1011 - learning_rate: 1.0000e-04 - epoch: 173.0000\n",
      "Epoch 174/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9693 - loss: 0.0953\n",
      "Epoch 174: Test Loss: 0.9039961695671082, Test Accuracy: 0.7370837926864624\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - accuracy: 0.9693 - loss: 0.0953 - learning_rate: 1.0000e-04 - epoch: 174.0000\n",
      "Epoch 175/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9762 - loss: 0.0773\n",
      "Epoch 175: Test Loss: 0.8544591665267944, Test Accuracy: 0.7566016316413879\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - accuracy: 0.9762 - loss: 0.0774 - learning_rate: 1.0000e-04 - epoch: 175.0000\n",
      "Epoch 176/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9774 - loss: 0.0753\n",
      "Epoch 176: Test Loss: 0.9095790982246399, Test Accuracy: 0.7451205253601074\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - accuracy: 0.9773 - loss: 0.0756 - learning_rate: 1.0000e-04 - epoch: 176.0000\n",
      "Epoch 177/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9705 - loss: 0.1066\n",
      "Epoch 177: Test Loss: 0.8598150610923767, Test Accuracy: 0.7600459456443787\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - accuracy: 0.9706 - loss: 0.1063 - learning_rate: 1.0000e-04 - epoch: 177.0000\n",
      "Epoch 178/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9695 - loss: 0.0965\n",
      "Epoch 178: Test Loss: 0.8210826516151428, Test Accuracy: 0.7657864689826965\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - accuracy: 0.9695 - loss: 0.0965 - learning_rate: 1.0000e-04 - epoch: 178.0000\n",
      "Epoch 179/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9711 - loss: 0.0877\n",
      "Epoch 179: Test Loss: 0.8939557671546936, Test Accuracy: 0.7428243160247803\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - accuracy: 0.9711 - loss: 0.0877 - learning_rate: 1.0000e-04 - epoch: 179.0000\n",
      "Epoch 180/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9694 - loss: 0.0997\n",
      "Epoch 180: Test Loss: 0.8444164991378784, Test Accuracy: 0.7566016316413879\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - accuracy: 0.9695 - loss: 0.0996 - learning_rate: 1.0000e-04 - epoch: 180.0000\n",
      "Epoch 181/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9811 - loss: 0.0775\n",
      "Epoch 181: Test Loss: 0.8710765242576599, Test Accuracy: 0.7520092129707336\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - accuracy: 0.9810 - loss: 0.0777 - learning_rate: 1.0000e-04 - epoch: 181.0000\n",
      "Epoch 182/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9778 - loss: 0.0806\n",
      "Epoch 182: Test Loss: 0.8305431604385376, Test Accuracy: 0.7600459456443787\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - accuracy: 0.9777 - loss: 0.0807 - learning_rate: 1.0000e-04 - epoch: 182.0000\n",
      "Epoch 183/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9762 - loss: 0.0874\n",
      "Epoch 183: Test Loss: 0.9121829271316528, Test Accuracy: 0.7428243160247803\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - accuracy: 0.9762 - loss: 0.0874 - learning_rate: 1.0000e-04 - epoch: 183.0000\n",
      "Epoch 184/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9771 - loss: 0.0826\n",
      "Epoch 184: Test Loss: 0.8410854935646057, Test Accuracy: 0.7611940503120422\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - accuracy: 0.9771 - loss: 0.0826 - learning_rate: 1.0000e-04 - epoch: 184.0000\n",
      "Epoch 185/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9787 - loss: 0.0782\n",
      "Epoch 185: Test Loss: 0.8650484085083008, Test Accuracy: 0.7554535269737244\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - accuracy: 0.9786 - loss: 0.0783 - learning_rate: 1.0000e-04 - epoch: 185.0000\n",
      "Epoch 186/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9800 - loss: 0.0776\n",
      "Epoch 186: Test Loss: 0.8703095316886902, Test Accuracy: 0.7588978409767151\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - accuracy: 0.9800 - loss: 0.0777 - learning_rate: 1.0000e-04 - epoch: 186.0000\n",
      "Epoch 187/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9752 - loss: 0.0849\n",
      "Epoch 187: Test Loss: 0.9509055614471436, Test Accuracy: 0.7313432693481445\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - accuracy: 0.9752 - loss: 0.0849 - learning_rate: 1.0000e-04 - epoch: 187.0000\n",
      "Epoch 188/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9767 - loss: 0.0816\n",
      "Epoch 188: Test Loss: 0.872395396232605, Test Accuracy: 0.7520092129707336\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - accuracy: 0.9767 - loss: 0.0817 - learning_rate: 1.0000e-04 - epoch: 188.0000\n",
      "Epoch 189/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9785 - loss: 0.0738\n",
      "Epoch 189: Test Loss: 0.9130192995071411, Test Accuracy: 0.7439724206924438\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - accuracy: 0.9785 - loss: 0.0739 - learning_rate: 1.0000e-04 - epoch: 189.0000\n",
      "Epoch 190/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9746 - loss: 0.0876\n",
      "Epoch 190: Test Loss: 0.7438676357269287, Test Accuracy: 0.7876004576683044\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - accuracy: 0.9747 - loss: 0.0875 - learning_rate: 1.0000e-04 - epoch: 190.0000\n",
      "Epoch 191/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9756 - loss: 0.0826\n",
      "Epoch 191: Test Loss: 0.7555633187294006, Test Accuracy: 0.7864523530006409\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - accuracy: 0.9756 - loss: 0.0827 - learning_rate: 1.0000e-04 - epoch: 191.0000\n",
      "Epoch 192/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9735 - loss: 0.0859\n",
      "Epoch 192: Test Loss: 0.8413684964179993, Test Accuracy: 0.7611940503120422\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - accuracy: 0.9736 - loss: 0.0858 - learning_rate: 1.0000e-04 - epoch: 192.0000\n",
      "Epoch 193/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9736 - loss: 0.0894\n",
      "Epoch 193: Test Loss: 0.7788926959037781, Test Accuracy: 0.780711829662323\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - accuracy: 0.9737 - loss: 0.0892 - learning_rate: 1.0000e-04 - epoch: 193.0000\n",
      "Epoch 194/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9745 - loss: 0.0840\n",
      "Epoch 194: Test Loss: 0.860018789768219, Test Accuracy: 0.7577497363090515\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - accuracy: 0.9745 - loss: 0.0838 - learning_rate: 1.0000e-04 - epoch: 194.0000\n",
      "Epoch 195/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9797 - loss: 0.0782\n",
      "Epoch 195: Test Loss: 0.8485772609710693, Test Accuracy: 0.764638364315033\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - accuracy: 0.9797 - loss: 0.0782 - learning_rate: 1.0000e-04 - epoch: 195.0000\n",
      "Epoch 196/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9830 - loss: 0.0758\n",
      "Epoch 196: Test Loss: 0.816245436668396, Test Accuracy: 0.7680826783180237\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.9829 - loss: 0.0758 - learning_rate: 1.0000e-04 - epoch: 196.0000\n",
      "Epoch 197/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9765 - loss: 0.0767\n",
      "Epoch 197: Test Loss: 0.8873195648193359, Test Accuracy: 0.7543054223060608\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9765 - loss: 0.0766 - learning_rate: 1.0000e-04 - epoch: 197.0000\n",
      "Epoch 198/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9720 - loss: 0.0919\n",
      "Epoch 198: Test Loss: 0.8889787197113037, Test Accuracy: 0.7474167346954346\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9721 - loss: 0.0917 - learning_rate: 1.0000e-04 - epoch: 198.0000\n",
      "Epoch 199/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9743 - loss: 0.0720\n",
      "Epoch 199: Test Loss: 0.8875573873519897, Test Accuracy: 0.7451205253601074\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9744 - loss: 0.0720 - learning_rate: 1.0000e-04 - epoch: 199.0000\n",
      "Epoch 200/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9730 - loss: 0.0867\n",
      "Epoch 200: Test Loss: 0.824965238571167, Test Accuracy: 0.764638364315033\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9730 - loss: 0.0867 - learning_rate: 1.0000e-04 - epoch: 200.0000\n",
      "Epoch 201/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9777 - loss: 0.0722\n",
      "Epoch 201: Test Loss: 0.8454046249389648, Test Accuracy: 0.7588978409767151\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9777 - loss: 0.0721 - learning_rate: 1.0000e-04 - epoch: 201.0000\n",
      "Epoch 202/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9833 - loss: 0.0660\n",
      "Epoch 202: Test Loss: 0.9050169587135315, Test Accuracy: 0.7416762113571167\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9832 - loss: 0.0661 - learning_rate: 1.0000e-04 - epoch: 202.0000\n",
      "Epoch 203/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9854 - loss: 0.0589\n",
      "Epoch 203: Test Loss: 0.7847774028778076, Test Accuracy: 0.7830080389976501\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.9853 - loss: 0.0590 - learning_rate: 1.0000e-04 - epoch: 203.0000\n",
      "Epoch 204/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9795 - loss: 0.0773\n",
      "Epoch 204: Test Loss: 0.7843389511108398, Test Accuracy: 0.7761194109916687\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.9794 - loss: 0.0773 - learning_rate: 1.0000e-04 - epoch: 204.0000\n",
      "Epoch 205/300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9743 - loss: 0.0766"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Callback for logging to CSV\n",
    "class CustomCSVLogger(Callback):\n",
    "    def __init__(self, filename):\n",
    "        super(CustomCSVLogger, self).__init__()\n",
    "        self.filename = filename\n",
    "        self.epoch = 1\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['epoch'] = self.epoch\n",
    "        self.epoch += 1\n",
    "        df = pd.DataFrame([logs])\n",
    "        if epoch == 0:\n",
    "            df.to_csv(self.filename, mode='w', index=False)\n",
    "        else:\n",
    "            df.to_csv(self.filename, mode='a', header=False, index=False)\n",
    "\n",
    "# Callback for testing evaluation\n",
    "class TestEvaluationCallback(Callback):\n",
    "    def __init__(self, test_data, test_log_filename):\n",
    "        self.test_data = test_data\n",
    "        self.test_log_filename = test_log_filename\n",
    "        self.test_loss = []\n",
    "        self.test_accuracy = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        test_loss, test_accuracy = self.model.evaluate(self.test_data[0], self.test_data[1], verbose=0)\n",
    "        self.test_loss.append(test_loss)\n",
    "        self.test_accuracy.append(test_accuracy)\n",
    "        print(f'\\nEpoch {epoch+1}: Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n",
    "        # Save test evaluation to CSV\n",
    "        with open(self.test_log_filename, 'a') as f:\n",
    "            f.write(f\"{epoch+1},{test_loss},{test_accuracy}\\n\")\n",
    "\n",
    "# Define paths\n",
    "csv_logger_v1 = \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\save_models\\\\save_models_csv\\\\v4.4.6_log_train_v1.csv\"\n",
    "test_log_v1 = \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\save_models\\\\save_models_csv\\\\v4.4.6_log_test_v1.csv\"\n",
    "model_filepath_v1 = \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\save_models\\\\save_models_keras\\\\v4.4.6_keras_v1.keras\"\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='accuracy', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=25, min_lr=0.0001)\n",
    "csv_logger = CustomCSVLogger(csv_logger_v1)\n",
    "model_checkpoint = ModelCheckpoint(filepath=model_filepath_v1, monitor='accuracy', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "test_eval_callback = TestEvaluationCallback((X_test, y_test), test_log_v1)\n",
    "\n",
    "# Initialize test log file with header\n",
    "with open(test_log_v1, 'w') as f:\n",
    "    f.write(\"epoch,test_loss,test_accuracy\\n\")\n",
    "\n",
    "# Train the model and save the logs to CSV\n",
    "hist_v1 = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=300,\n",
    "    batch_size=64,\n",
    "    callbacks=[\n",
    "        # early_stopping,\n",
    "        reduce_lr,\n",
    "        model_checkpoint,\n",
    "        csv_logger,\n",
    "        test_eval_callback\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da30189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muat data dari file CSV\n",
    "try:\n",
    "    history_df = pd.read_csv(csv_logger_v1)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File tidak ditemukan di path: {csv_logger_v1}\")\n",
    "    history_df = None\n",
    "\n",
    "try:\n",
    "    test_history_df = pd.read_csv(test_log_v1)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File tidak ditemukan di path: {test_log_v1}\")\n",
    "    test_history_df = None\n",
    "\n",
    "if history_df is not None and test_history_df is not None:\n",
    "    # Dapatkan jumlah epoch dari panjang data\n",
    "    epochs = range(1, len(history_df) + 1)\n",
    "\n",
    "    # Plot akurasi dan loss\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.suptitle(\"Senin, 29 Juli - Training Model\", fontsize=20)\n",
    "\n",
    "    # Plot Akurasi Training, Validasi & Testing\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history_df['accuracy'], label='Training Accuracy', color='blue')\n",
    "    # plt.plot(epochs, history_df['val_accuracy'], label='Validation Accuracy', color='green')\n",
    "    plt.plot(test_history_df['epoch'], test_history_df['test_accuracy'], label='Test Accuracy', color='red')  # Plot Test Accuracy per epoch\n",
    "    plt.title('Model Accuracy', fontsize=15)\n",
    "    plt.xlabel('Epochs', fontsize=12)\n",
    "    plt.ylabel('Accuracy', fontsize=12)\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot Loss Training, Validasi & Testing\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history_df['loss'], label='Training Loss', color='blue')\n",
    "    # plt.plot(epochs, history_df['val_loss'], label='Validation Loss', color='green')\n",
    "    plt.plot(test_history_df['epoch'], test_history_df['test_loss'], label='Test Loss', color='red')  # Plot Test Loss per epoch\n",
    "    plt.title('Model Loss', fontsize=15)\n",
    "    plt.xlabel('Epochs', fontsize=12)\n",
    "    plt.ylabel('Loss', fontsize=12)\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb18dbc",
   "metadata": {},
   "source": [
    "Code dibawah digunakan untuk melanjutkan training - 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8667c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Callback for logging to CSV\n",
    "class CustomCSVLogger(Callback):\n",
    "    def __init__(self, filename, initial_epoch=1):\n",
    "        super(CustomCSVLogger, self).__init__()\n",
    "        self.filename = filename\n",
    "        self.epoch = initial_epoch\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['epoch'] = self.epoch\n",
    "        self.epoch += 1\n",
    "        df = pd.DataFrame([logs])\n",
    "        if epoch == 0 and self.epoch == 2:\n",
    "            df.to_csv(self.filename, mode='w', index=False)\n",
    "        else:\n",
    "            df.to_csv(self.filename, mode='a', header=False, index=False)\n",
    "\n",
    "# Callback for testing evaluation\n",
    "class TestEvaluationCallback(Callback):\n",
    "    def __init__(self, test_data, test_log_filename, initial_epoch=1):\n",
    "        self.test_data = test_data\n",
    "        self.test_log_filename = test_log_filename\n",
    "        self.initial_epoch = initial_epoch\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        test_loss, test_accuracy = self.model.evaluate(self.test_data[0], self.test_data[1], verbose=0)\n",
    "        print(f'\\nEpoch {epoch+1}: Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n",
    "        # Save test evaluation to CSV\n",
    "        with open(self.test_log_filename, 'a') as f:\n",
    "            f.write(f\"{epoch+1},{test_loss},{test_accuracy}\\n\")\n",
    "\n",
    "# Define paths\n",
    "csv_logger_v1 = \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\save_models\\\\save_models_csv\\\\v4.4.6_log_train_v1.csv\"\n",
    "test_log_v1 = \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\save_models\\\\save_models_csv\\\\v4.4.6_log_test_v1.csv\"\n",
    "model_filepath_v1 = \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\save_models\\\\save_models_keras\\\\v4.4.6_keras_v1.keras\"\n",
    "\n",
    "# Load the last saved model\n",
    "try:\n",
    "    model = tf.keras.models.load_model(model_filepath_v1)\n",
    "    print(\"Model loaded from checkpoint.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load model from checkpoint: {e}\")\n",
    "\n",
    "# Determine the last epoch trained\n",
    "try:\n",
    "    history_df = pd.read_csv(csv_logger_v1)\n",
    "    initial_epoch = history_df['epoch'].max()\n",
    "except FileNotFoundError:\n",
    "    print(f\"File tidak ditemukan di path: {csv_logger_v1}\")\n",
    "    history_df = None\n",
    "    initial_epoch = 1\n",
    "\n",
    "try:\n",
    "    test_history_df = pd.read_csv(test_log_v1)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File tidak ditemukan di path: {test_log_v1}\")\n",
    "    test_history_df = None\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='accuracy', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=25, min_lr=0.0001)\n",
    "csv_logger = CustomCSVLogger(csv_logger_v1, initial_epoch=initial_epoch + 1)\n",
    "model_checkpoint = ModelCheckpoint(filepath=model_filepath_v1, monitor='accuracy', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "test_eval_callback = TestEvaluationCallback((X_test, y_test), test_log_v1, initial_epoch=initial_epoch + 1)\n",
    "\n",
    "# Train the model and save the logs to CSV\n",
    "hist_v1 = model.fit(\n",
    "    X_train, y_train,\n",
    "    # validation_data=(X_val, y_val),\n",
    "    epochs=initial_epoch + 50,  # change this to the desired number of total epochs\n",
    "    batch_size=64,\n",
    "    initial_epoch=initial_epoch,\n",
    "    callbacks=[\n",
    "        # early_stopping,\n",
    "        reduce_lr,\n",
    "        model_checkpoint,\n",
    "        csv_logger,\n",
    "        test_eval_callback\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bced1047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muat data dari file CSV\n",
    "try:\n",
    "    history_df = pd.read_csv(csv_logger_v1)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File tidak ditemukan di path: {csv_logger_v1}\")\n",
    "    history_df = None\n",
    "\n",
    "try:\n",
    "    test_history_df = pd.read_csv(test_log_v1)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File tidak ditemukan di path: {test_log_v1}\")\n",
    "    test_history_df = None\n",
    "\n",
    "if history_df is not None and test_history_df is not None:\n",
    "    # Dapatkan jumlah epoch dari panjang data\n",
    "    epochs = range(1, len(history_df) + 1)\n",
    "\n",
    "    # Plot akurasi dan loss\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.suptitle(\"Senin, 29 Juli - Training Model\", fontsize=20)\n",
    "\n",
    "    # Plot Akurasi Training, Validasi & Testing\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history_df['accuracy'], label='Training Accuracy', color='blue')\n",
    "    # plt.plot(epochs, history_df['val_accuracy'], label='Validation Accuracy', color='green')\n",
    "    plt.plot(test_history_df['epoch'], test_history_df['test_accuracy'], label='Test Accuracy', color='red')  # Plot Test Accuracy per epoch\n",
    "    plt.title('Model Accuracy', fontsize=15)\n",
    "    plt.xlabel('Epochs', fontsize=12)\n",
    "    plt.ylabel('Accuracy', fontsize=12)\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot Loss Training, Validasi & Testing\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history_df['loss'], label='Training Loss', color='blue')\n",
    "    # plt.plot(epochs, history_df['val_loss'], label='Validation Loss', color='green')\n",
    "    plt.plot(test_history_df['epoch'], test_history_df['test_loss'], label='Test Loss', color='red')  # Plot Test Loss per epoch\n",
    "    plt.title('Model Loss', fontsize=15)\n",
    "    plt.xlabel('Epochs', fontsize=12)\n",
    "    plt.ylabel('Loss', fontsize=12)\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bd2800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, log_loss, accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve, average_precision_score, precision_recall_curve\n",
    "from itertools import cycle\n",
    "\n",
    "# Prediksi menggunakan model pada data uji\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_probabilities = tf.nn.softmax(y_pred).numpy()  # Terapkan softmax secara eksplisit jika perlu\n",
    "y_pred_classes = np.argmax(y_pred_probabilities, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Hitung metrik evaluasi\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "precision = precision_score(y_true_classes, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_true_classes, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
    "log_loss_value = log_loss(y_true_classes, y_pred_probabilities)\n",
    "\n",
    "# Print metrik evaluasi\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Log Loss: {log_loss_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ff61fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tampilkan classification report yang lengkap\n",
    "report = classification_report(y_true_classes, y_pred_classes, target_names=AKSARA)\n",
    "print(report)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "# Normalisasi confusion matrix untuk mendapatkan persentase\n",
    "conf_matrix_normalized = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Tampilkan confusion matrix sebagai heatmap\n",
    "plt.figure(figsize=(18, 15))\n",
    "sns.heatmap(conf_matrix_normalized, annot=True, fmt=\".2%\", cmap=\"YlGnBu\", xticklabels=AKSARA, yticklabels=AKSARA)\n",
    "plt.xlabel(\"Predicted Aksara\")\n",
    "plt.ylabel(\"Actual Aksara\")\n",
    "plt.title(\"Confusion Matrix (Percentage)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00a6cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hitung AUC-ROC untuk setiap kelas\n",
    "# auc_roc_scores = roc_auc_score(y_test, y_pred_probabilities, average=None)\n",
    "# for idx, score in enumerate(auc_roc_scores):\n",
    "#     print(f\"AUC-ROC for class {AKSARA[idx]}: {score:.4f}\")\n",
    "\n",
    "# # Tampilkan ROC Curve untuk setiap kelas\n",
    "# fpr = dict()\n",
    "# tpr = dict()\n",
    "# roc_auc = dict()\n",
    "# n_classes = len(AKSARA)\n",
    "# colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'blue', 'purple', 'pink', 'brown', 'grey', \n",
    "#                 'cyan', 'magenta', 'yellow', 'black', 'lime', 'navy', 'gold', 'teal', 'salmon', 'olive'])\n",
    "\n",
    "# plt.figure(figsize=(10, 8))\n",
    "\n",
    "# for i, color in zip(range(n_classes), colors):\n",
    "#     fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred_probabilities[:, i])\n",
    "#     roc_auc[i] = roc_auc_score(y_test[:, i], y_pred_probabilities[:, i])\n",
    "#     plt.plot(fpr[i], tpr[i], color=color, lw=2, label=f'ROC curve of class {AKSARA[i]} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver Operating Characteristic (ROC) Curve for each class')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83ecc9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hitung AUPRC untuk setiap kelas\n",
    "# average_precision = dict()\n",
    "# precision_recall_curves = dict()\n",
    "\n",
    "# plt.figure(figsize=(10, 8))\n",
    "\n",
    "# for i, color in zip(range(n_classes), colors):\n",
    "#     precision_recall_curves[i], recall, _ = precision_recall_curve(y_test[:, i], y_pred_probabilities[:, i])\n",
    "#     average_precision[i] = average_precision_score(y_test[:, i], y_pred_probabilities[:, i])\n",
    "#     plt.plot(recall, precision_recall_curves[i], color=color, lw=2, label=f'PR curve of class {AKSARA[i]} (area = {average_precision[i]:.2f})')\n",
    "\n",
    "# plt.xlabel('Recall')\n",
    "# plt.ylabel('Precision')\n",
    "# plt.title('Precision-Recall Curve for each class')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00678533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the function to display images with predictions\n",
    "def display_images_with_predictions(images, true_labels, predictions, labels, max_images=50):\n",
    "    num_images = min(len(images), max_images)\n",
    "    cols = 5\n",
    "    rows = (num_images + cols - 1) // cols  # Compute number of rows needed\n",
    "\n",
    "    plt.figure(figsize=(15, 3 * rows))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(images[i].squeeze(), cmap='gray')\n",
    "        \n",
    "        # Check if prediction is correct\n",
    "        correct = true_labels[i] == predictions[i]\n",
    "        result = \"Correct\" if correct else \"Incorrect\"\n",
    "        color = \"green\" if correct else \"red\"\n",
    "        \n",
    "        # Adjust title to avoid overlapping\n",
    "        plt.title(\n",
    "            f\"True: {labels[true_labels[i]]} || Pred: {labels[predictions[i]]}\\n{result}\",\n",
    "            color=color,\n",
    "            fontsize=12,  # Set font size\n",
    "            pad=5  # Add padding to title\n",
    "        )\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Load the trained model\n",
    "# model_path = \"C:\\\\Users\\\\USER-03\\\\W\\\\projects_s\\\\save_models\\\\save_models_h5\\\\v4.2.7_model1.h5\"\n",
    "model = load_model(model_filepath_v1)\n",
    "\n",
    "# Perform predictions\n",
    "y_pred_probabilities = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred_probabilities, axis=1)\n",
    "\n",
    "# Convert one-hot encoded y_test to class indices if needed\n",
    "if y_test.ndim == 2:\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "else:\n",
    "    y_test_classes = y_test\n",
    "\n",
    "# Display some test images with predictions\n",
    "display_images_with_predictions(X_test, y_test_classes, y_pred_classes, AKSARA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e74678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the custom preprocessing function\n",
    "def apply_custom_preprocessing(image):\n",
    "    # Convert image to uint8 if not already\n",
    "    if image.dtype != np.uint8:\n",
    "        image = np.uint8(image)\n",
    "        \n",
    "    # Apply Gaussian Blur\n",
    "    ApplyGaussian = cv2.GaussianBlur(image, (15, 15), 0.1)\n",
    "    # Enhance the image sharpness\n",
    "    img = cv2.addWeighted(image, 1.5, ApplyGaussian, -0.5, 0, image)\n",
    "    # Apply sharpening filter\n",
    "    kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
    "    img = cv2.filter2D(img, -1, kernel)\n",
    "    # Remove noise using median filter\n",
    "    img = cv2.medianBlur(img, 1)\n",
    "    # Apply Otsu's thresholding\n",
    "    _, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    # Invert the image (background to black, text to white)\n",
    "    img = 255 - img\n",
    "    \n",
    "    # Apply dilation to thicken the lines\n",
    "    kernel = np.ones((2, 2), np.uint8)  # You can adjust the kernel size\n",
    "    img = cv2.dilate(img, kernel, iterations=1)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Define the function to preprocess the image\n",
    "def preprocess_image(img_path, image_size):\n",
    "    # Load the image\n",
    "    img = image.load_img(img_path, target_size=image_size, color_mode='grayscale')\n",
    "    # Convert the image to array\n",
    "    img_array = image.img_to_array(img)\n",
    "    \n",
    "    # Apply custom preprocessing\n",
    "    img_array_preprocessed = apply_custom_preprocessing(img_array)\n",
    "    \n",
    "    # Normalize the image\n",
    "    img_array_preprocessed = img_array_preprocessed.astype(\"float32\") / 255.0\n",
    "    # Expand dimensions to match input shape\n",
    "    img_array_preprocessed = np.expand_dims(img_array_preprocessed, axis=-1)\n",
    "    img_array_preprocessed = np.expand_dims(img_array_preprocessed, axis=0)\n",
    "    \n",
    "    return img_array_preprocessed\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(model_filepath_v1)  # Replace with your model path\n",
    "\n",
    "# Path to the test image\n",
    "test_image_path = \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\data\\\\data_original\\\\CustomData\\\\data_prediction\\\\nya14.png\"\n",
    "image_size = IMAGE_SIZE\n",
    "\n",
    "# Preprocess the image\n",
    "preprocessed_image = preprocess_image(test_image_path, image_size)\n",
    "\n",
    "# Perform the prediction\n",
    "output = model.predict(preprocessed_image)\n",
    "\n",
    "# Find the index of the maximum value in the output\n",
    "pos = np.argmax(output)\n",
    "\n",
    "# Print the result based on the index\n",
    "print(\"Prediction output:\\n\", output)\n",
    "print(\"Score: \", output[0][pos])\n",
    "\n",
    "# Define a variable to store the predicted label\n",
    "predicted_label = \"\"\n",
    "\n",
    "# Print the class based on the position using if-elif\n",
    "if pos == 0:\n",
    "    predicted_label = \"ba\"\n",
    "elif pos == 1:\n",
    "    predicted_label = 'ca'\n",
    "elif pos == 2:\n",
    "    predicted_label = 'da'\n",
    "elif pos == 3:\n",
    "    predicted_label = 'dha'\n",
    "elif pos == 4:\n",
    "    predicted_label = 'ga'\n",
    "elif pos == 5:\n",
    "    predicted_label = 'ha'\n",
    "elif pos == 6:\n",
    "    predicted_label = 'ja'\n",
    "elif pos == 7:\n",
    "    predicted_label = 'ka'\n",
    "elif pos == 8:\n",
    "    predicted_label = 'la'\n",
    "elif pos == 9:\n",
    "    predicted_label = 'ma'\n",
    "elif pos == 10:\n",
    "    predicted_label = 'na'\n",
    "elif pos == 11:\n",
    "    predicted_label = 'nga'\n",
    "elif pos == 12:\n",
    "    predicted_label = 'nya'\n",
    "elif pos == 13:\n",
    "    predicted_label = 'pa'\n",
    "elif pos == 14:\n",
    "    predicted_label = 'ra'\n",
    "elif pos == 15:\n",
    "    predicted_label = 'sa'\n",
    "elif pos == 16:\n",
    "    predicted_label = 'ta'\n",
    "elif pos == 17:\n",
    "    predicted_label = 'tha'\n",
    "elif pos == 18:\n",
    "    predicted_label = 'wa'\n",
    "elif pos == 19:\n",
    "    predicted_label = 'ya'\n",
    "\n",
    "# Print the predicted label\n",
    "print(\"Aksara: \", predicted_label)\n",
    "\n",
    "# Display the preprocessed image with prediction\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "# Preprocessed Image\n",
    "preprocessed_for_display = apply_custom_preprocessing(image.img_to_array(image.load_img(test_image_path, target_size=image_size, color_mode='grayscale')))\n",
    "plt.imshow(preprocessed_for_display.squeeze(), cmap='gray')\n",
    "plt.title(f\"Predicted: {predicted_label} || Score: {output[0][pos]:.8f}\")\n",
    "plt.axis('on')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4044ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the custom preprocessing function\n",
    "def apply_custom_preprocessing(image):\n",
    "    # Convert image to uint8 if not already\n",
    "    # if image.dtype != np.uint8:\n",
    "    #     image = np.uint8(image)\n",
    "        \n",
    "    # Apply Gaussian Blur\n",
    "    ApplyGaussian = cv2.GaussianBlur(image, (15, 15), 0.1)\n",
    "    # Enhance the image sharpness\n",
    "    img = cv2.addWeighted(image, 1.5, ApplyGaussian, -0.5, 0, image)\n",
    "    # Apply sharpening filter\n",
    "    kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
    "    img = cv2.filter2D(img, -1, kernel)\n",
    "    # Remove noise using median filter\n",
    "    img = cv2.medianBlur(img, 1)\n",
    "    # Apply Otsu's thresholding\n",
    "    _, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    # Invert the image (background to black, text to white)\n",
    "    img = 255 - img\n",
    "    \n",
    "    # Apply dilation to thicken the lines\n",
    "    kernel = np.ones((2, 2), np.uint8)  # You can adjust the kernel size\n",
    "    img = cv2.dilate(img, kernel, iterations=1)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Define the function to preprocess the image\n",
    "def preprocess_image(img_path, image_size):\n",
    "    # Load the image\n",
    "    img = image.load_img(img_path, target_size=image_size, color_mode='grayscale')\n",
    "    # Convert the image to array\n",
    "    img_array = image.img_to_array(img)\n",
    "    \n",
    "    # Apply custom preprocessing\n",
    "    img_array_preprocessed = apply_custom_preprocessing(img_array)\n",
    "    \n",
    "    # Normalize the image\n",
    "    img_array_preprocessed = img_array_preprocessed.astype(\"float32\") / 255.0\n",
    "    # Expand dimensions to match input shape\n",
    "    img_array_preprocessed = np.expand_dims(img_array_preprocessed, axis=-1)\n",
    "    img_array_preprocessed = np.expand_dims(img_array_preprocessed, axis=0)\n",
    "    \n",
    "    return img_array_preprocessed, img_array\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(model_filepath_v1)  # Replace with your model path\n",
    "\n",
    "# Path to the test image\n",
    "test_image_path = \"C:\\\\Users\\\\M S I\\\\W\\\\projects_skripsi\\\\data\\\\data_original\\\\CustomData\\\\data_prediction\\\\nya14.png\"\n",
    "image_size = IMAGE_SIZE\n",
    "\n",
    "# Preprocess the image\n",
    "preprocessed_image, original_image = preprocess_image(test_image_path, image_size)\n",
    "\n",
    "# Perform the prediction\n",
    "output = model.predict(preprocessed_image)\n",
    "\n",
    "# Find the index of the maximum value in the output\n",
    "max_val = output[0][0]\n",
    "pos = 0\n",
    "for i in range(1, len(output[0])):\n",
    "    if output[0][i] > max_val:\n",
    "        max_val = output[0][i]\n",
    "        pos = i\n",
    "\n",
    "# Print the result based on the index\n",
    "print(\"Prediction output:\\n\", output)\n",
    "print(\"Score: \", max_val)\n",
    "\n",
    "# Define labels\n",
    "labels = ['ba', 'ca', 'da', 'dha', 'ga', 'ha', 'ja', 'ka', 'la', 'ma', \n",
    "          'na', 'nga', 'nya', 'pa', 'ra', 'sa', 'ta', 'tha', 'wa', 'ya']\n",
    "predicted_label = labels[pos]\n",
    "print(\"Aksara: \", predicted_label)\n",
    "\n",
    "# Display the preprocessed image with prediction\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "# Preprocessed Image\n",
    "preprocessed_for_display = apply_custom_preprocessing(image.img_to_array(image.load_img(test_image_path, target_size=image_size, color_mode='grayscale')))\n",
    "plt.imshow(preprocessed_for_display.squeeze(), cmap='gray')\n",
    "plt.title(f\"Predicted: {predicted_label} || Score: {max_val:.8f}\")\n",
    "plt.axis('on')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
