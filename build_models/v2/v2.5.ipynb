{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch torchvision\n",
    "# pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "PATH = '../data/data_preprocessing/v0.8/augmented'\n",
    "images, labels = [], []\n",
    "\n",
    "for dirname, _, filenames in os.walk(PATH):\n",
    "    for filename in filenames:\n",
    "        images.append(os.path.join(dirname, filename).split('/')[-1])  # /folder/blabla/xxx.jpg\n",
    "        labels.append(os.path.basename(dirname))  # Menggunakan nama folder sebagai label\n",
    "\n",
    "# Menggunakan np.unique untuk mendapatkan kelas unik\n",
    "# label2cat = np.unique(labels)\n",
    "# print(\"Kelas :\", label2cat)\n",
    "\n",
    "# Membuat kamus untuk memetakan label ke kelas numerik\n",
    "# label_to_numeric = {label: idx for idx, label in enumerate(label2cat)}\n",
    "# print(\"Kamus Label ke Numerik:\", label_to_numeric)\n",
    "# label_to_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    image_id label\n",
      "0  augmented\\ba\\ba116.pred3.b_aug_0_1033.png    ba\n",
      "1  augmented\\ba\\ba116.pred3.b_aug_0_1069.png    ba\n",
      "2  augmented\\ba\\ba116.pred3.b_aug_0_1077.png    ba\n",
      "3  augmented\\ba\\ba116.pred3.b_aug_0_1095.png    ba\n",
      "4  augmented\\ba\\ba116.pred3.b_aug_0_1097.png    ba\n",
      "Bentuk DataFrame: (9860, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Membuat DataFrame dari daftar gambar dan label\n",
    "datas = pd.DataFrame({'image_id': images, 'label': labels})\n",
    "\n",
    "# Menampilkan lima baris pertama dan bentuk DataFrame\n",
    "print(datas.head())\n",
    "print(\"Bentuk DataFrame:\", datas.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6902, 1479, 1479)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Memisahkan data menjadi data latih (train) dan data uji (test)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     datas['image_id'].values, datas['label'].values, \n",
    "#     test_size=0.3, stratify=datas['label'].values, \n",
    "#     random_state=42)\n",
    "\n",
    "# # Menampilkan jumlah data latih dan data uji\n",
    "# print(\"Jumlah data latih:\", len(X_train))\n",
    "# print(\"Jumlah data uji:\", len(X_test))\n",
    "# # len(X_train), len(X_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    datas['image_id'].values, datas['label'].values, \n",
    "    test_size=0.3, stratify=datas['label'].values, \n",
    "    random_state=24)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val,\n",
    "    test_size=0.5, stratify=y_val, \n",
    "    random_state=24)\n",
    "\n",
    "\n",
    "len(X_train), len(X_val), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class customDataset(Dataset):\n",
    "    def __init__(self, x, y, path, maps_label=label_to_numeric, transform=None):\n",
    "        self.X = x\n",
    "        self.y = y\n",
    "        self.path = path\n",
    "        self.label_to_numeric = maps_label\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # img = Image.open(self.path + str(self.y[idx]) + '/' + str(self.X[idx])).convert('RGB')\n",
    "        img = Image.open(self.path + str(self.y[idx]) + '/' + str(self.X[idx]))\n",
    "        img = img.convert('L')  # Mengonversi gambar ke citra grayscale\n",
    "        label = self.y[idx]\n",
    "        label = self.label_2_ints(label)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return img, label\n",
    "    \n",
    "    def label_2_ints(self, x):\n",
    "        label_id = None\n",
    "        for key, values in self.label_to_numeric.items():\n",
    "            if x == key:\n",
    "                label_id = values\n",
    "        return label_id\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "crop_size = 224\n",
    "bs = 64\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(crop_size, scale=(0.9, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(230),\n",
    "    transforms.CenterCrop(crop_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "train_set = customDataset(X_train, y_train, PATH, transform=train_transform)\n",
    "trainloader = DataLoader(train_set, batch_size=bs, shuffle=True, num_workers=2)\n",
    "\n",
    "val_set = customDataset(X_val, y_val, PATH, transform=val_transform)\n",
    "valloader = DataLoader(val_set, batch_size=bs, shuffle=True)\n",
    "\n",
    "test_set = customDataset(X_test, y_test, PATH, transform=val_transform)\n",
    "testloader = DataLoader(test_set, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature, target = next(iter(trainloader))\n",
    "feature.shape, len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,5, figsize=(15, 7))\n",
    "for img, label, ax in zip(feature, target, axes.flatten()):\n",
    "  ax.imshow(img.permute(1,2,0).cpu())\n",
    "  font = {\"color\":'g'}\n",
    "  label = label2cat[label.item()]\n",
    "  ax.set_title(f\"Label: {label}\", fontdict=font);\n",
    "  ax.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMobileNetv2(nn.Module):\n",
    "  def __init__(self, output_size):\n",
    "    super().__init__()\n",
    "    self.mnet = mobilenet_v2(pretrained=True)\n",
    "    self.freeze()\n",
    "\n",
    "    self.mnet.classifier = nn.Sequential(\n",
    "        nn.Linear(1280, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, output_size),\n",
    "        nn.LogSoftmax(1)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.mnet(x)\n",
    "  \n",
    "  def freeze(self):\n",
    "    for param in self.mnet.parameters():\n",
    "      param.requires_grad = False\n",
    "\n",
    "  def unfreeze(self):\n",
    "    for param in self.mnet.parameters():\n",
    "      param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = set_config({\n",
    "    'batch_size': bs,\n",
    "    'crop_size': crop_size,\n",
    "    'output_size': len(label2cat)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomMobileNetv2(config.output_size).to(device)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "callback = Callback(model, config, early_stop_patience=2, outdir='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_fn(mode, dataset, dataloader, model, criterion, optimizer, device):\n",
    "  if mode == 'train':\n",
    "    model.train()\n",
    "  elif mode == 'val':\n",
    "    model.eval()\n",
    "  \n",
    "  cost = correct = 0\n",
    "  for feature, target in dataloader:\n",
    "    feature, target = feature.to(device), target.to(device)\n",
    "    output = model(feature)\n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    if mode == 'train':\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "    \n",
    "    cost += loss.item() * feature.shape[0]\n",
    "    correct += (output.argmax(1) == target).sum().item()\n",
    "  cost = cost/len(dataset)\n",
    "  acc = correct/len(dataset)\n",
    "  return cost, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "  train_cost, train_score = loop_fn('train', train_set, trainloader, model, criterion, optimizer, device)\n",
    "  with torch.no_grad():\n",
    "    test_cost, test_score = loop_fn('val', val_set, valloader, model, criterion, optimizer, device)\n",
    "\n",
    "  # Logging\n",
    "  callback.log(train_cost, test_cost, train_score, test_score)\n",
    "\n",
    "  # Checkpoint\n",
    "  callback.save_checkpoint()\n",
    "\n",
    "  # Runtime Plotting\n",
    "  callback.cost_runtime_plotting()\n",
    "  callback.score_runtime_plotting()\n",
    "\n",
    "  # Early Stopping\n",
    "  if callback.early_stopping(model, monitor='test_score'):\n",
    "    callback.plot_cost()\n",
    "    callback.plot_score()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.unfreeze()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "callback.reset_early_stop()\n",
    "callback.early_stop_patience = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "  train_cost, train_score = loop_fn('train', train_set, trainloader, model, criterion, optimizer, device)\n",
    "  with torch.no_grad():\n",
    "    test_cost, test_score = loop_fn('val', val_set, valloader, model, criterion, optimizer, device)\n",
    "\n",
    "  # Logging\n",
    "  callback.log(train_cost, test_cost, train_score, test_score)\n",
    "\n",
    "  # Checkpoint\n",
    "  callback.save_checkpoint()\n",
    "\n",
    "  # Runtime Plotting\n",
    "  callback.cost_runtime_plotting()\n",
    "  callback.score_runtime_plotting()\n",
    "\n",
    "  # Early Stopping\n",
    "  if callback.early_stopping(model, monitor='test_score'):\n",
    "    callback.plot_cost()\n",
    "    callback.plot_score()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, target in valloader:\n",
    "  feature, target = feature.to(device), target.to(device)\n",
    "  with torch.no_grad():\n",
    "    model.eval()\n",
    "    output = model(feature)\n",
    "    preds = output.argmax(1)\n",
    "\n",
    "fig, axes = plt.subplots(6, 6, figsize=(24, 24))\n",
    "for img, label, pred, ax in zip(feature, target, preds, axes.flatten()):\n",
    "  ax.imshow(img.permute(1,2,0).cpu())\n",
    "  font = {\"color\":'r'} if label != pred else {\"color\": 'g'}\n",
    "  label, pred = label2cat[label.item()], label2cat[pred.item()]\n",
    "  ax.set_title(f\"Label: {label}\\nPred: {pred}\", fontdict=font);\n",
    "  ax.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "for feature, target in testloader:\n",
    "  feature, target = feature.to(device), target.to(device)\n",
    "  with torch.no_grad():\n",
    "    model.eval()\n",
    "    output = model(feature)\n",
    "    preds = output.argmax(1)\n",
    "    if(target == preds):\n",
    "      acc = 1\n",
    "    else: acc = 0\n",
    "    accuracy.append(acc)\n",
    "accuracy = np.array(accuracy)\n",
    "accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Jawo(Dataset):\n",
    "#     def __init__(self, x, y, path, maps_label=dicts, transform=None):\n",
    "#         self.X = x\n",
    "#         self.y = y\n",
    "#         self.path = path\n",
    "#         self.dicts = maps_label\n",
    "#         self.transform = transform\n",
    "        \n",
    "#     def __getitem__(self, idx):\n",
    "#         img = Image.open(self.path + str(self.y[idx]) + '/' + str(self.X[idx])).convert('RGB')\n",
    "#         label = self.y[idx]\n",
    "#         label = self.label_2_ints(label)\n",
    "        \n",
    "#         if self.transform is not None:\n",
    "#             img = self.transform(img)\n",
    "            \n",
    "#         return img, label\n",
    "    \n",
    "#     def label_2_ints(self, x):\n",
    "#         label_id = None\n",
    "#         for key, values in self.dicts.items():\n",
    "#             if x == key:\n",
    "#                 label_id = values\n",
    "#         return label_id\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     datas['image_id'].values, datas['label'].values, \n",
    "#     test_size=0.3, stratify=datas['label'].values, \n",
    "#     random_state=24)\n",
    "\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_val, y_val,\n",
    "#     test_size=0.5, stratify=y_val, \n",
    "#     random_state=24)\n",
    "\n",
    "\n",
    "# len(X_train), len(X_val), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class customDataset(Dataset):\n",
    "#     def __init__(self, x, y, path, maps_label=dicts, transform=None):\n",
    "#         self.X = x\n",
    "#         self.y = y\n",
    "#         self.path = path\n",
    "#         self.dicts = maps_label\n",
    "#         self.transform = transform\n",
    "        \n",
    "#     def __getitem__(self, idx):\n",
    "#         img = Image.open(self.path + str(self.y[idx]) + '/' + str(self.X[idx])).convert('RGB')\n",
    "#         label = self.y[idx]\n",
    "#         label = self.label_2_ints(label)\n",
    "        \n",
    "#         if self.transform is not None:\n",
    "#             img = self.transform(img)\n",
    "            \n",
    "#         return img, label\n",
    "    \n",
    "#     def label_2_ints(self, x):\n",
    "#         label_id = None\n",
    "#         for key, values in self.dicts.items():\n",
    "#             if x == key:\n",
    "#                 label_id = values\n",
    "#         return label_id\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
